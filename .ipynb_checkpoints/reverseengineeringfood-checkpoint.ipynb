{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595548fe-4b17-4dfc-ab3d-e2d5ecb66ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca331584-386a-4b05-82c3-5d49ece9df99",
   "metadata": {},
   "source": [
    "idea: Reverse Engineering From Nutrition Labels\n",
    "1. create equations --> system of equations. now need to optimize system of equations (can't solve because # ingredients doesn't\n",
    "always equal # of equations (14 in this case, reason for 14 explained below). Can optimize with gradient descent.\n",
    "2. perform gradient descent (create loss function, gradients, gradient loss function, update variable values)\n",
    "3. randomize initial gradient descent inputs\n",
    "4. choose solution with lowest loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8889c5e6-ce96-465f-99c0-b326ccaff005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the overall dictionary: the one representing the nutrition label facts. I will copy this dictionary for any \n",
    "#ingredient I use.\n",
    "\n",
    "overall_dict = {}\n",
    "\n",
    "overall_dict[\"Fat\"] = 0\n",
    "overall_dict[\"Saturated fatty acids\"] = 0\n",
    "overall_dict[\"Fatty acids, total trans\"] = 0\n",
    "overall_dict[\"Cholesterol\"] = 0\n",
    "overall_dict[\"Sodium\"] = 0\n",
    "overall_dict[\"Carbohydrate\"] = 0\n",
    "overall_dict[\"Fiber\"] = 0\n",
    "overall_dict[\"Sugars\"] = 0\n",
    "overall_dict[\"Protein\"] = 0\n",
    "overall_dict[\"Calcium\"] = 0\n",
    "overall_dict[\"Iron\"] = 0\n",
    "overall_dict[\"Potassium\"] = 0\n",
    "overall_dict[\"Vitamin D\"] = 0\n",
    "overall_dict[\"Weight\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c79466a-e91f-4889-bc15-c2cf3512fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nutritional information for tates cookies per 10 grams (each number was initially for  28 grams. So I had to multiply \n",
    "#each number by (10 * (1 / 28)) to get the information for 10 grams)\n",
    "\n",
    "tates_dict = overall_dict.copy()\n",
    "tates_dict[\"Fat\"] = 7 * (10 * (1 / 28))\n",
    "tates_dict[\"Saturated fatty acids\"] = 4.5 * (10 * (1 / 28))\n",
    "tates_dict[\"Fatty acids, total trans\"] = 0 * (10 * (1 / 28))\n",
    "tates_dict[\"Cholesterol\"] = .025 * (10 * (1 / 28))\n",
    "tates_dict[\"Sodium\"] = .16 * (10 * (1 / 28))\n",
    "tates_dict[\"Carbohydrate\"] = 18 * (10 * (1 / 28))\n",
    "tates_dict[\"Fiber\"] = .8 * (10 * (1 / 28))\n",
    "tates_dict[\"Sugars\"] = 12 * (10 * (1 / 28))\n",
    "tates_dict[\"Protein\"] = 2 * (10 * (1 / 28))\n",
    "tates_dict[\"Calcium\"] = .0000001 * (10 * (1 / 28))\n",
    "tates_dict[\"Iron\"] = .0009 * (10 * (1 / 28))\n",
    "tates_dict[\"Potassium\"] = .01 * (10 * (1 / 28))\n",
    "tates_dict[\"Vitamin D\"] = .05 * (10 * (1 / 28))\n",
    "tates_dict[\"Weight\"] = 28 * (10 * (1 / 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197d9c9b-66b6-4f1c-8163-b12ab2cf6175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fat': 2.4999999999999996,\n",
       " 'Saturated fatty acids': 1.607142857142857,\n",
       " 'Fatty acids, total trans': 0.0,\n",
       " 'Cholesterol': 0.008928571428571428,\n",
       " 'Sodium': 0.057142857142857134,\n",
       " 'Carbohydrate': 6.428571428571428,\n",
       " 'Fiber': 0.2857142857142857,\n",
       " 'Sugars': 4.285714285714285,\n",
       " 'Protein': 0.7142857142857142,\n",
       " 'Calcium': 3.5714285714285705e-08,\n",
       " 'Iron': 0.00032142857142857136,\n",
       " 'Potassium': 0.003571428571428571,\n",
       " 'Vitamin D': 0.017857142857142856,\n",
       " 'Weight': 9.999999999999998}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tates_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a8e71d-eda2-4f84-a689-07cdca25c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform the website information to dictionaries (with the keys of overall_dict). takes\n",
    "# into account varying weight units (g/mg/mcg)\n",
    "\n",
    "#examples used to test this function\n",
    "\n",
    "file1 = \"flour_unbleached_enriched_allpurpose_wheat.csv\"\n",
    "file2 = \"butter_salted.csv\"\n",
    "\n",
    "ingredient_dict = overall_dict.copy()\n",
    "\n",
    "def reader(file,ingredient_dict,desired_serving):\n",
    "    with open(file, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for i,row in enumerate(csvreader):\n",
    "            if len(row) > 0 and row[0] in ingredient_dict:\n",
    "                if row[2] == \"mg\":\n",
    "                    ingredient_dict[row[0]] = (float(row[1]) / 1000) * desired_serving\n",
    "                elif row[2] == \"mcg\":\n",
    "                    ingredient_dict[row[0]] = (float(row[1]) / 1000000) * desired_serving\n",
    "                else: #grams\n",
    "                    ingredient_dict[row[0]] = (float(row[1])) * desired_serving\n",
    "            if i == 4:\n",
    "                index = row.index(\"g\")\n",
    "                ingredient_dict[\"Weight\"] = float(row[index-1]) * desired_serving\n",
    "    return ingredient_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff597840-d25e-4934-9168-8ddae6bc16c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fat': 16.222,\n",
       " 'Saturated fatty acids': 10.274,\n",
       " 'Fatty acids, total trans': 0.656,\n",
       " 'Cholesterol': 0.043,\n",
       " 'Sodium': 0.1286,\n",
       " 'Carbohydrate': 0.02,\n",
       " 'Fiber': 0.0,\n",
       " 'Sugars': 0.02,\n",
       " 'Protein': 0.18,\n",
       " 'Calcium': 0.0048,\n",
       " 'Iron': 0.0,\n",
       " 'Potassium': 0.0048,\n",
       " 'Vitamin D': 0.0,\n",
       " 'Weight': 20.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader(file2,ingredient_dict,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a59a8580-87b3-4ada-84a2-5378341e5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the various ingredients in Tate's. Transforming the online nutrritional information of each ingredient into individual dictionaries.\n",
    "\n",
    "desired_serving = 1\n",
    "\n",
    "semi_sweet_chocolate_file = \"semisweet_chocolate_chips_by_raleys.csv\"\n",
    "semi_sweet_chocolate_dict = overall_dict.copy()\n",
    "reader(semi_sweet_chocolate_file,semi_sweet_chocolate_dict,desired_serving)\n",
    "\n",
    "unbleached_flour_file = \"flour_unbleached_enriched_allpurpose_wheat.csv\"\n",
    "unbleached_flour_dict = overall_dict.copy()\n",
    "reader(unbleached_flour_file,unbleached_flour_dict,desired_serving)\n",
    "\n",
    "salted_butter_file = \"butter_salted.csv\"\n",
    "salted_butter_dict = overall_dict.copy()\n",
    "reader(salted_butter_file,salted_butter_dict,desired_serving)\n",
    "\n",
    "cane_sugar_file = \"granulated_pure_cane_sugar.csv\"\n",
    "cane_sugar_dict = overall_dict.copy()\n",
    "reader(cane_sugar_file,cane_sugar_dict,desired_serving)\n",
    "\n",
    "brown_cane_sugar_file = \"brown_sugar_cane_by_frusecha.csv\"\n",
    "brown_cane_sugar_dict = overall_dict.copy()\n",
    "reader(brown_cane_sugar_file,brown_cane_sugar_dict,desired_serving)\n",
    "\n",
    "eggs_file = \"egg_fresh_raw_whole.csv\"\n",
    "eggs_dict = overall_dict.copy()\n",
    "reader(eggs_file,eggs_dict,desired_serving)\n",
    "\n",
    "baking_soda_file = \"leavening_agents_baking_soda.csv\"\n",
    "baking_soda_dict = overall_dict.copy()\n",
    "reader(baking_soda_file,baking_soda_dict,desired_serving)\n",
    "\n",
    "salt_file = \"salt_table.csv\"\n",
    "salt_dict = overall_dict.copy()\n",
    "reader(salt_file,salt_dict,desired_serving)\n",
    "\n",
    "natural_vanilla_flavor_file = \"vanilla_flavoring_syrup_by_r_torre__coinc.csv\"\n",
    "natural_vanilla_flavor_dict = overall_dict.copy()\n",
    "reader(natural_vanilla_flavor_file,natural_vanilla_flavor_dict,desired_serving)\n",
    "\n",
    "vanilla_extract_file = \"vanilla_extract.csv\"\n",
    "vanilla_extract_dict = overall_dict.copy()\n",
    "reader(vanilla_extract_file,vanilla_extract_dict,desired_serving)\n",
    "\n",
    "dictionary_list = [semi_sweet_chocolate_dict,unbleached_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict,baking_soda_dict,salt_dict,vanilla_extract_dict]\n",
    "key_list_old = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Sodium\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\",\"Weight\"]\n",
    "key_list_meh = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\"]\n",
    "key_list = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\"]\n",
    "key_list_try = [\"Fat\",\"Saturated fatty acids\",\"Cholesterol\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48da4db-13b4-4ac2-9651-687f6068a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of whatever inputted number (with a length of dictionary_list (number of variables))\n",
    "\n",
    "def building_x_list(number,dictionary_list):\n",
    "    x_list = []\n",
    "    for variable in range(0, len(dictionary_list)):\n",
    "        x_list.append(number)\n",
    "    return x_list\n",
    "\n",
    "x_list = building_x_list(1,dictionary_list)\n",
    "\n",
    "#equations function (using Tate's cookies as an example): using the nutrition label (in this case, tates_dict), we're\n",
    "#given the amount of macro and micronutrients in a serving of Tate's cookies. I changed these values to have the \n",
    "#dictionary output the amount of each macro/micronutrient in grams and for a serving of 10g of Tate's cookies.\n",
    "#We're also given the ingredients in the cookies (bottom of nutrition label) and this is represented by dictionary_list.\n",
    "#Each ingredient gets its own dictionary list, as I imported the micro/macronutrient information for each individual\n",
    "#ingredient. Each ingredient dictionary reports the micro/macro information for each ingredient in grams and for a \n",
    "#serving of 10g. So now, with this information, we can build a system of equations with each equation corresponding to\n",
    "#each micro/macronutrient (so each key value in the dictionaries). Each equation has variables x0,x1,...,x13 (14 variables)\n",
    "#with xn representing the amount of the nth indexed ingredient in the dictionary_list (so x0 is the amount of semi-sweet \n",
    "#chocolate, x1 is the amount of flour, etc.). Each equation has all 14 variables, their respective coefficients, and what\n",
    "#the equation equals. So for the first equation (which corresponds to the fat values), each variable's coefficient is the amount of \n",
    "#fat in that variable's corresponding ingredient. So if equation one looked like a0x0 + a1x1 + ... + a13x13 = C1:\n",
    "#x0 is the amount of chocolate in 10g of Tate's cookies, a0 is the amount of fat in 10g of chocolate, x1 is the amount of flour\n",
    "#in 10g of Tate's cookies, a1 is the amount of fat in 10g of flour, etc, and C1 is the amount of fat in 10g of Tate's cookies. equation one\n",
    "#is for fat, equation two is for saturated fat, etc.\n",
    "\n",
    "#so now for the equations function, I bring each Cn to the left side of the equation (so a0x0 + a1x1 + ... + a13x13 = C1\n",
    "# goes to a0x0 + a1x1 + ... + a13x13 - C1, so instead of an equation I now have an expression. The equation function\n",
    "#evaluates each expression. The function outputs a list with the value of each evaluated expression in order of key_list. \n",
    "# So this means the fat equation has index 0, saturated fat has index 1, etc. in the outputted list. Ideally, each expression should \n",
    "#evaluate to 0.\n",
    "\n",
    "def equations(dictionary_list,x_list,desired_dict):\n",
    "    list_of_equations = []\n",
    "    for key in key_list:\n",
    "        equation = 0\n",
    "        for i,dictionary in enumerate(dictionary_list):\n",
    "            equation = equation + (dictionary[key] * (x_list[i]))\n",
    "        #subtracting the constant that the equation equals (a0x0 + a1x1 + ... + a13x13 = C1 -->  a0x0 + a1x1 + ... + a13x13 - C1)\n",
    "        list_of_equations.append(equation-(desired_dict[key]*desired_serving))\n",
    "    return list_of_equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c382ee-5f9c-4944-83b2-72fd5873ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradients function: because each equation has variables with the highest degrees of one, the gradients with respect to each variable\n",
    "#for each equation is just the coefficient of that variable. As stated above, this coefficient is just the respective value in \n",
    "#that variable (ingredient)'s key for that specific micro/macronutrient (which corresponds to equation number)\n",
    "#basically, I'm saying that for the fat equation, the equation is a0x0 + a1x1 + ... + a13x13 = C. The\n",
    "#derivative of the equation with respect to x0 is just a0. The gradients function would output a list for this first equation,\n",
    "#with each index filled with the partial derivative of the equation with respect to the variable that has the same index of the list.\n",
    "#So if the first equation is a0x0 + a1x1 + ... + a13x13 = C, the first list would be [a0,a1,...,a13].\n",
    "#The function therefore outputs multiple lists (14), with each list being a list of the coefficients \n",
    "#corresponding to a macro/micronutrient (first list --> fat, second list --> saturated fat, etc., so the order of these lists is the \n",
    "#order of key_list. Stated again but maybe more simply: The first list is a list of partial derivatives of the first equation, and the \n",
    "#list is in order of partial derivatives of x0,...,x13. The second list is a list of partial derivatives of the second equation, etc. \n",
    "#The returned list is a list of all these lists.\n",
    "\n",
    "def gradients(dictionary_list,x_list):\n",
    "    list_of_gradients_of_equations = []\n",
    "    for key in key_list:\n",
    "        gradient = []\n",
    "        for dictionary in dictionary_list:\n",
    "            gradient.append(dictionary[key])\n",
    "        list_of_gradients_of_equations.append(gradient)\n",
    "    return list_of_gradients_of_equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8032fe0c-5eda-40ff-8540-2142f5029e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the parameters that I'm implementing. Each ingredient value must be greater than 0 and because the nutrition\n",
    "#label gives a list of ingredients in descending order, x0 > x1, x1> x2, etc. \n",
    "\n",
    "#the parameters function returns values if any of the variables violate the parameters. The function returns a list of 15 lists.\n",
    "#The first 14 lists look at the parameters relating to the ingredients in descending order. The last list\n",
    "#looks at the parameter of being greater than 0.\n",
    "\n",
    "#For the first 14 lists, I had to choose how to \"punish\" the variables. If x0 < x1 < x2, do I \"punish\" all three variables\n",
    "#looking at x0 < x1, x1 < x2, and x0 < x2? Or do I just look at the neighboring variables, so only having the violations be\n",
    "#x0< x1 and x1<x2. It made more sense for me to do the latter, so for each neighboring violation, both variables are equally \"punished.\"\n",
    "#So, for the first list, every number should be 0 except for the first and second variables (0th and 1st index of the list) if \n",
    "#the x0 < x1. This is because the first list only looks at the first two variables. Then the second list looks at the second and third\n",
    "#variables. etc.\n",
    "\n",
    "\n",
    "def parameters(x_list,penalty_constant,dictionary_list):\n",
    "    list_of_parameters = []\n",
    "    list_of_parameters_over_0 = []\n",
    "    for i in range(0,len(x_list)-1):\n",
    "        parameter_for_over_0 = penalty_constant * ((max(0,(-1 * x_list[i]))) ** 2)\n",
    "        list_of_parameters_over_0.append(parameter_for_over_0)\n",
    "        parameter_for_inequality_individual_variable_list = building_x_list(0,dictionary_list)\n",
    "        parameter_for_inequalities = penalty_constant * ((max(0, x_list[i+1] - x_list[i])) ** 2)\n",
    "        parameter_for_inequality_individual_variable_list[i] = parameter_for_inequality_individual_variable_list[i] + (parameter_for_inequalities / 2)\n",
    "        parameter_for_inequality_individual_variable_list[i+1] = parameter_for_inequality_individual_variable_list[i+1]+ (parameter_for_inequalities / 2)\n",
    "        list_of_parameters.append(parameter_for_inequality_individual_variable_list)\n",
    "\n",
    "    #the last variable. because my above loop goes from 0 to the n-1 variable. \n",
    "    list_of_parameters_over_0.append(10 * (max(0,-x_list[-1]) ** 2))\n",
    "    list_of_parameters.append(list_of_parameters_over_0)\n",
    "\n",
    "    return list_of_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3197fa65-76ff-4b82-a8d6-a715c7deba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the gradient function for the parameters. I'm just taking the partial derivatives of the parameter expressions\n",
    "#I have above (in the parameters function). The function outputs a list containing 15 lists. Each list corresponds\n",
    "#to the list of the same index in the parameters function (so the first list, or 0th index, is the partial derivatives \n",
    "#of the first list (or 0th index) outputted from the parameters function). Because each of the first 14 list has 0 entries\n",
    "#except for (possibly-if they violate the parameter) two indices, the gradients list outputted that corresponds to that list\n",
    "#also has 0 entries for everything but those two indices.\n",
    "\n",
    "\n",
    "\n",
    "def gradients_of_parameters(x_list,penalty_constant,dictionary_list):\n",
    "    list_of_gradients_of_parameters = []\n",
    "    list_gradient_over_0 = building_x_list(0,dictionary_list)\n",
    "    for i in range(0,len(x_list)-1):\n",
    "        list_gradient_over_0[i] = (2 * penalty_constant) * max(0, -x_list[i])\n",
    "        penalty_gradients_inequalities = building_x_list(0,dictionary_list)\n",
    "        penalty_gradients_inequalities[i] = penalty_gradients_inequalities[i] + ((-2 * penalty_constant) * max(0, x_list[i+1] - x_list[i]))\n",
    "        penalty_gradients_inequalities[i+1] = (2 * penalty_constant) * max(0, x_list[i+1] - x_list[i])\n",
    "        list_of_gradients_of_parameters.append(penalty_gradients_inequalities)\n",
    "    list_gradient_over_0[-1] = (-2 * penalty_constant) * max(0, -x_list[-1])\n",
    "\n",
    "    #this is where gradient for over 0 goes. so this is the last list\n",
    "    list_of_gradients_of_parameters.append(list_gradient_over_0)\n",
    "    \n",
    "    return list_of_gradients_of_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d88ec8cc-25d3-4140-af2e-878a50f2604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to normalize the gradients because initially, the gradients were growing too fast.\n",
    "#normalizing the gradients makes the input of a penalty constant much less significant.\n",
    "\n",
    "def normalize_gradients(gradients):\n",
    "    norm = np.linalg.norm(gradients)\n",
    "    if norm > 0:\n",
    "        return [g / norm for g in gradients]\n",
    "    return gradients\n",
    "\n",
    "#loss function: calculates the loss, looking at to what extent the inputted variables violate the equation expressions (how far\n",
    "#from 0 does the expression evaluate to) and the parameters.\n",
    "\n",
    "def loss_function(dictionary_list,x_list,penalty_constant,desired_dict):\n",
    "    list_of_equations = equations(dictionary_list,x_list,desired_dict)\n",
    "    list_of_parameters = parameters(x_list,penalty_constant,dictionary_list)\n",
    "    loss = 0\n",
    "    for equation in list_of_equations:\n",
    "        loss = loss + (equation ** 2)\n",
    "    for parameter in list_of_parameters:\n",
    "        loss = loss + (np.sum(parameter))\n",
    "    return loss\n",
    "\n",
    "\n",
    "#gradient loss function: first, the function adds the gradient lists from the equations and parameters to get a\n",
    "#list of 29 (14 + 15) lists. In each of these lists, the index of the gradient determines what variable it corresponds to\n",
    "#(as said above, for example, gradient in index of one in any of these lists corresponds to the semi-sweet chocolate variable, x0).\n",
    "#The function outputs one list, and each index in this list is: the sum of each equation multiplied by that index in all 29 the \n",
    "#gradient lists. Then, the final list is normalized.\n",
    "\n",
    "def gradient_loss_function(dictionary_list,x_list,penalty_constant,desired_dict):\n",
    "    list_of_equations = equations(dictionary_list,x_list,desired_dict)\n",
    "    list_of_gradients_of_equations = gradients(dictionary_list,x_list)\n",
    "    list_of_gradients_of_parameters = gradients_of_parameters(x_list,penalty_constant,dictionary_list)\n",
    "    list_of_gradients_loss = building_x_list(0,dictionary_list)\n",
    "    list_of_gradients = list_of_gradients_of_equations + list_of_gradients_of_parameters\n",
    "    \n",
    "    for equation in list_of_equations:\n",
    "        for gradient_list_in_question in list_of_gradients:\n",
    "            for j in range(0,len(gradient_list_in_question)):\n",
    "                list_of_gradients_loss[j] = list_of_gradients_loss[j] + (2 * gradient_list_in_question[j] * equation)\n",
    "    list_of_gradients_loss = normalize_gradients(list_of_gradients_loss)\n",
    "    return list_of_gradients_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6fe3a9f-3bc0-4931-b759-c8fc05408fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "\n",
    "#this is the function that updates the inputted variables list (and updates it max_iters amount of times (unless the outputted\n",
    "#loss is within .00006 of the one before it, then the function breaks)). First, the gradients_loss_function and loss_function are\n",
    "# evaluated. Then for each index in the inputted variables list, the function alters the existing list, subtracting (the learning\n",
    "#rate * the gradient_loss_list value at that index) from the current value. Then the loss function is calculated again.\n",
    "\n",
    "#if graphing == True, then the loss with respect to the number of iterations is graphed.\n",
    "\n",
    "#if light == True, that means that there are \"light\" ingredients that I want to restrain. This is because ingredients like \n",
    "#vanilla extract or baking soda barely have macro/micronutrients, so its a lot harder to account for them in the system of equations.\n",
    "#But, to ensure that they don't go \"crazy\", I limit their values.\n",
    "\n",
    "\n",
    "def updating_x_values(dictionary_list,x_listy,penalty_constant,desired_dict,max_iters,serving,light,graphing):\n",
    "    \n",
    "    if graphing == True:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(0,max_iters):\n",
    "        \n",
    "        gradient_loss_list = gradient_loss_function(dictionary_list,x_listy,penalty_constant,desired_dict)\n",
    "        loss_before = loss_function(dictionary_list,x_listy,penalty_constant,desired_dict)\n",
    "        \n",
    "        for j in range(0,len(x_listy)):\n",
    "            x_listy[j] = x_listy[j] - (learning_rate * gradient_loss_list[j])\n",
    "            \n",
    "            \n",
    "            if light == True:\n",
    "                x_listy[j] = max(x_listy[j],0)\n",
    "                x_listy[-1] = min(x_listy[-1],.004)\n",
    "                x_listy[-2] = min(x_listy[-2],.004)\n",
    "                x_listy[-3] = min(x_listy[-3],.004)\n",
    "                \n",
    "        loss_after = loss_function(dictionary_list,x_listy,penalty_constant,desired_dict)\n",
    "        \n",
    "        if graphing == True:\n",
    "            plt.plot(i,loss_after,\"om\")\n",
    "            \n",
    "        if loss_before - loss_after < .00006:\n",
    "            if graphing == True:\n",
    "                print(\"breaking at: \" + str(i))\n",
    "            break\n",
    "        \n",
    "    if graphing == True:\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"iterations\")\n",
    "        plt.show()\n",
    "        print(\"Solution:\", x_listy)\n",
    "        print(\"Loss at solution:\", loss_after)\n",
    "        x_for_one_serving = []\n",
    "        for x in x_listy:\n",
    "            x_for_one_serving.append(x * serving)\n",
    "        print(\"for one serving (in g):\", x_for_one_serving)\n",
    "        print(\"weight:\", np.sum(x_listy) * 10)\n",
    "        \n",
    "    return loss_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13582545-09fe-46ea-8fff-00f3bf018444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what if we did this but just with the heavy ingredients (so exluding vanilla, baking soda, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "996054c2-9c62-46d8-b797-f23dd4a9a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slightly adjusting the weight of the tate's cookies serving\n",
    "\n",
    "heavy_tates_dict = tates_dict.copy()\n",
    "heavy_tates_dict[\"Weight\"] += -.01\n",
    "\n",
    "#altering the dictionary list to exclude the \"light\" ingredients (so excluding vanilla, salt, and baking soda)\n",
    "heavy_dictionary_list = [semi_sweet_chocolate_dict,unbleached_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c6374b-fa58-4257-be00-cffe158326e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the outputs are very similar. So, I decided to continue including the light ingredients and just put light == True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1314c008-c274-465f-b068-5bfcd1fb86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now looking at the tates gluten-free cookies.\n",
    "#the nutritional information is very similar to the non-gluten-free cookies I looked at above, except flour is replaced with \n",
    "#rice flour, xantham gum is added, and very minor changes are made to the micro/macronutrient values.\n",
    "\n",
    "tates_dict_gluten_free = overall_dict.copy()\n",
    "tates_dict_gluten_free[\"Fat\"] = 7 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Saturated fatty acids\"] = 4.5 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Fatty acids, total trans\"] = 0 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Cholesterol\"] = .020 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Sodium\"] = .135 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Carbohydrate\"] = 19 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Fiber\"] = .8 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Sugars\"] = 12 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Protein\"] = 1 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Calcium\"] = .01 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Iron\"] = .0007 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Potassium\"] = .04 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Vitamin D\"] = .0 * (10 * (1 / 28))\n",
    "tates_dict_gluten_free[\"Weight\"] = 28 * (10 * (1 / 28))\n",
    "\n",
    "rice_flour_file = \"rice_flour_unenriched_white.csv\"\n",
    "rice_flour_dict = overall_dict.copy()\n",
    "reader(rice_flour_file,rice_flour_dict,desired_serving)\n",
    "\n",
    "xanthan_gum_file = \"xanthan_gum_by_namaste.csv\"\n",
    "xanthan_gum_dict = overall_dict.copy()\n",
    "reader(xanthan_gum_file,xanthan_gum_dict,desired_serving)\n",
    "\n",
    "dictionary_list_gluten_free = [semi_sweet_chocolate_dict,rice_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict,natural_vanilla_flavor_dict,baking_soda_dict,salt_dict,xanthan_gum_dict]\n",
    "dictionary_list_gluten_free_heavy = [semi_sweet_chocolate_dict,rice_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e27d21a-67f7-47cc-a644-38b1bdb05cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outputs + loss heeavily depends on the initial input. So what if we randomize the inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd05239-06bc-400f-b438-c69d017d749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function returns a list of sorted (from increasing to decreasing) random values to act as the x_list input. \n",
    "#These random values are floats between 0 and 1 and all sum to 1.\n",
    "\n",
    "def generate_random_floats(dictionary_list):\n",
    "    random_values = np.random.uniform(0, 1, len(dictionary_list))\n",
    "    \n",
    "    # Normalize so their sum equals 1\n",
    "    normalized_values = random_values / np.sum(random_values)\n",
    "    \n",
    "    lst = normalized_values.tolist()\n",
    "    lsty = sorted(lst,reverse=True)\n",
    "    return lsty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2da9df4d-755f-4132-95b9-f68ef0da8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing the updating_x_values function on random x_list inputs. The amount of random x_list inputs tried is the \n",
    "#random_iterations variable. The function conducts the updating_x_values function for a random input, and gets the\n",
    "#loss from the solution list. Then the function does it for random_iterations number of random x_lists. the function\n",
    "#outputs the random list whose solution generates the lowest loss and the corresponding solution.\n",
    "\n",
    "#the function also graphs the lowest loss so far with the number of random x_list iterations.\n",
    "\n",
    "def finding_the_best_from_randomized(dictionary_list,penalty_constant,desired_dict,random_iterations,gradient_iterations,serving,light,graphing):\n",
    "    loss_list = []\n",
    "    lowest_loss = 5\n",
    "    lowest_loss_x_values = []\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(0,random_iterations):\n",
    "        x_list = generate_random_floats(dictionary_list)\n",
    "        loss = updating_x_values(dictionary_list,x_list,penalty_constant,desired_dict,gradient_iterations,serving,light,graphing)\n",
    "        if loss < lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            lowest_loss_x_values = x_list\n",
    "        plt.plot(i,lowest_loss,\"or\")\n",
    "    plt.xlabel(\"number of random x_lists looked at\")\n",
    "    plt.ylabel(\"lowest loss so far\")\n",
    "    plt.show()\n",
    "    serving_list = []\n",
    "    for number in lowest_loss_x_values:\n",
    "        serving_list.append(number * serving) \n",
    "\n",
    "    print(\"lowest loss: \", lowest_loss)\n",
    "    print(\"solution: \", lowest_loss_x_values)\n",
    "    print(\"solution in terms of serving size (in g): \", serving_list)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cabbc840-c148-4cc2-a299-0371f0b5fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps... try other food products other than Tate's. Prioritize foods with less add-ins like dyes, extracts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bda802ac-570d-44ed-9be1-5abf7648fe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# larabar:\n",
    "desired_serving = 1\n",
    "\n",
    "lara_bar_dict = overall_dict.copy()\n",
    "lara_bar_dict[\"Fat\"] = 9 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Saturated fatty acids\"] = 1.5 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Fatty acids, total trans\"] = 0 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Cholesterol\"] = 0 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Sodium\"] = .005 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Carbohydrate\"] = 27 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Fiber\"] = 3 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Sugars\"] = 17 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Protein\"] = 4 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Calcium\"] = 0 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Iron\"] = .0017 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Potassium\"] = .3 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Vitamin D\"] = .0 * (10 * (1 / 45))\n",
    "lara_bar_dict[\"Weight\"] = 45 * (10 * (1 / 45))\n",
    "\n",
    "cashew_file = \"cashews.csv\"\n",
    "cashew_dict = overall_dict.copy()\n",
    "reader(cashew_file,cashew_dict,desired_serving)\n",
    "\n",
    "dates_file = \"date.csv\"\n",
    "dates_dict = overall_dict.copy()\n",
    "reader(dates_file,dates_dict,desired_serving)\n",
    "\n",
    "apples_file = \"apples_with_skin_raw.csv\"\n",
    "apples_dict = overall_dict.copy()\n",
    "reader(apples_file,apples_dict,desired_serving)\n",
    "\n",
    "blueberries_file = \"blueberries_raw.csv\"\n",
    "blueberries_dict = overall_dict.copy()\n",
    "reader(blueberries_file,blueberries_dict,desired_serving)\n",
    "\n",
    "lara_bar_dictionary_list = [cashew_dict,dates_dict,apples_dict,blueberries_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330e3c85-364a-41bf-b202-41fbe5a85d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error from abs of difference:  0.11051951175980974\n",
      "error from squaring the difference 0.00319206219241987\n"
     ]
    }
   ],
   "source": [
    "#trying something: looking at the bon appetite copycat recipe vs. guess (only heavy).\n",
    "\n",
    "bon_appetite_list_goal = [340,240,227,150,165,100]\n",
    "for i in range(0,len(bon_appetite_list_goal)):\n",
    "    bon_appetite_list_goal[i] = bon_appetite_list_goal[i] / 1242\n",
    "    \n",
    "actual_list = [0.3138914625298704, 0.22226880232707666, 0.20756861329992468, 0.12170302584377322, 0.12472600258064327, 0.08801006766670016]\n",
    "error_squared = 0\n",
    "error_subtracted = 0\n",
    "\n",
    "for i in range(0,len(bon_appetite_list_goal)):\n",
    "    error_subtracted = error_subtracted + abs((bon_appetite_list_goal[i] - actual_list[i]))\n",
    "    error_squared = error_squared + ((bon_appetite_list_goal[i] - actual_list[i]) ** 2)\n",
    "\n",
    "print(\"error from abs of difference: \", error_subtracted)\n",
    "print(\"error from squaring the difference\", error_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d19a0667-6b21-432e-b42b-36d3158605fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.078157825750356"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the loss of the \"actual values\": the bon appetite copy cat recipe\n",
    "\n",
    "loss_function(heavy_dictionary_list,bon_appetite_list_goal,1,heavy_tates_dict)\n",
    "\n",
    "#the copy cat recipe has a loss of 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846061a8-7abc-42a5-b70c-bf6a561c7256",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "- because manufacturing companies don't release their exact ingredient makeup, it's hard to measure how \"right\" I was.\n",
    "So, I looked at my loss function as the indicator, with a loss close to 0 signifying \"rightness.\"\n",
    "- ingredients like vanilla extract or baking soda were hard to determine due to the lack of nutritional information they\n",
    "have (Ex. both have 0g carbohydrates, 0g fat, 0g protein, etc.) and therefore, my model was not the best at predicting these\n",
    "values (unless I clipped them). Using gradient descent to optimize these equations works most optimally for products\n",
    "with little add-ins (dyes, extracts, etc. that have little micro/macronutrient information).\n",
    "- maybe I could take this project future, expanding to pharmaceutical labels and breaking down those labels.\n",
    "- the poster link (summarizing background,methods,results,limitations,conclusion,and references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc4056b3-2ff2-4dfe-8649-cf655b67ddff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"650\"\n",
       "            src=\"reverse_engineering_food_products final_poster.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10616ec30>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"reverse_engineering_food_products final_poster.pdf\", width=900, height=650)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d52656-c7e7-4996-92a2-8983c44b7453",
   "metadata": {},
   "source": [
    "next steps: comparing with built-inn python optimizers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ce0a84-e6f6-47e1-8219-a3e4050f6475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 21:38:54.072507: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#1: tf.train.*Optimizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6b9613f-ab1f-40a9-b298-daed2234740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables_tf(n):\n",
    "    # Random positive values \n",
    "    initial_values = tf.random.uniform(shape=(n,), minval=0.0, maxval=1.0)\n",
    "    \n",
    "    # Sort in descending order\n",
    "    initial_values = tf.sort(initial_values, direction='DESCENDING')\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    #initial_values = initial_values / tf.reduce_sum(initial_values)\n",
    "    \n",
    "    return tf.Variable(initial_values, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "163652cc-115c-4688-aced-474902c52774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try changing the loss\n",
    "\n",
    "def loss_tf(predicted):\n",
    "    \n",
    "    #descending_penalty = tf.reduce_sum(tf.nn.relu(predicted[:-1] - predicted[1:]))\n",
    "    \n",
    "    #return tf.reduce_mean(tf.square(predicted)) + (10 * descending_penalty)\n",
    "    return tf.reduce_mean(tf.square(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c95eb41e-c7eb-4e49-8fb1-35e504a670e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_tf(dictionary_list,target_dict):\n",
    "\n",
    "    n = len(dictionary_list)\n",
    "    variables_tf = initialize_variables_tf(n)    \n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Training loop\n",
    "    for epoch in range(200):  # Number of epochs\n",
    "        with tf.GradientTape() as tape:\n",
    "        # Step 1: Evaluate the equations\n",
    "             predictions1 = equations(dictionary_list,variables_tf,target_dict)\n",
    "             predictions = tf.convert_to_tensor(predictions1)\n",
    "        # Step 2: Compute the loss\n",
    "             loss = loss_tf(predictions)\n",
    "\n",
    "    # Step 3: Compute gradients\n",
    "        gradients = tape.gradient(loss, [variables_tf])\n",
    "\n",
    "    # Step 4: Apply gradients to update variables\n",
    "        optimizer.apply_gradients(zip(gradients, [variables_tf]))\n",
    "\n",
    "    # Apply constraints\n",
    "    # 1. Ensure all variables are positive\n",
    "        variables_tf.assign(tf.maximum(variables_tf, 0.0))\n",
    " \n",
    "        #variables_tf.assign(variables_tf / tf.reduce_sum(variables_tf))\n",
    "    \n",
    "    # 2. Ensure variables are in descending order\n",
    "        #variables_tf.assign(tf.sort(variables_tf, direction='DESCENDING'))\n",
    "\n",
    "    # Optional: Print progress\n",
    "        #if epoch % 20 == 0:  # Print every 20 epochs\n",
    "            #print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, Variables: {variables_tf.numpy()}\")\n",
    "\n",
    "    x_for_one_serving = []\n",
    "    for x in variables_tf.numpy():\n",
    "        x_for_one_serving.append(x * 1242)\n",
    "    #print(x_for_one_serving)\n",
    "\n",
    "    return (variables_tf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db7aa286-fe6e-4b00-9389-4e454bcf5c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.21444127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.45623532, 0.21444127, 0.1532272 , 0.11708368, 0.07847041,\n",
       "       0.03975484], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_tf(heavy_dictionary_list,tates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b5f8249-9310-43b4-9d1a-2fc7d315ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 20\n",
    "def multiple_times(iterations,dictionary_list,target_dict):\n",
    "    list = building_x_list(0,dictionary_list)\n",
    "    for i in range(0,iterations):\n",
    "        current_array = running_tf(heavy_dictionary_list,target_dict)\n",
    "        for j in range(0,len(current_array)):\n",
    "            list[j] = list[j] + current_array[j]\n",
    "    for k in range(0,len(current_array)):\n",
    "        list[k] = list[k] / iterations\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e165c3-f064-465a-9ca9-78325231a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_times(20,heavy_dictionary_list,tates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2a3a9e91-13ab-4149-be85-3df61ebad368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_much_sodium_needed(dictionary_list,desired_dict):\n",
    "    optimized_heavy_list = multiple_times(20,heavy_dictionary_list,tates_dict)\n",
    "    \n",
    "    equation = 0\n",
    "    key = key_list_old[4]\n",
    "    print(key)\n",
    "    for i,dictionary in enumerate(dictionary_list):\n",
    "        equation = equation + (dictionary[key] * (optimized_heavy_list[i]))\n",
    "    #subtracting the constant that the equation equals (a0x0 + a1x1 + ... + a13x13 = C1 -->  a0x0 + a1x1 + ... + a13x13 - C1)\n",
    "    print((desired_dict[key]*desired_serving),\"this is tates\")\n",
    "    print(optimized_heavy_list)\n",
    "    return (desired_dict[key]*desired_serving) -equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1c4ffcb-b033-45fa-87c2-8c9fa447c0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sodium\n",
      "0.057142857142857134 this is tates\n",
      "[0.4947484344244003, 0.19919266328215599, 0.13721138685941697, 0.10883750524371863, 0.06740383943542838, 0.07400253876112402]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0471896518520758"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_much_sodium_needed(heavy_dictionary_list,tates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "324af950-687d-40dc-80d1-51e9b6bf3bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.4775555551051\n",
      "247.39728779643772\n",
      "170.41654247939587\n",
      "135.17618151269855\n",
      "83.71556857880205\n",
      "91.91115314131603\n"
     ]
    }
   ],
   "source": [
    "list = [0.4947484344244003, 0.19919266328215599, 0.13721138685941697, 0.10883750524371863, 0.06740383943542838, 0.07400253876112402]\n",
    "for i in range(0,len(list)):\n",
    "    print(list[i] * 1242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b82d8519-99ae-48ec-b92b-7378c40c1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_much_weight_lost(dictionary_list,desired_dict):\n",
    "    optimized_heavy_list = [0.4947484344244003, 0.19919266328215599, 0.13721138685941697, 0.10883750524371863, 0.06740383943542838, 0.07400253876112402]\n",
    "    equation = 0\n",
    "    key = key_list_old[-1]\n",
    "    for i,dictionary in enumerate(dictionary_list):\n",
    "        equation = equation + (dictionary[key] * (optimized_heavy_list[i]))\n",
    "        print(equation)\n",
    "    #subtracting the constant that the equation equals (a0x0 + a1x1 + ... + a13x13 = C1 -->  a0x0 + a1x1 + ... + a13x13 - C1)\n",
    "    return (equation - desired_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "17ab947f-9330-4cef-8e24-10db3ae0cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.947484344244003\n",
      "6.939410977065563\n",
      "8.311524845659733\n",
      "9.399899898096919\n",
      "10.073938292451203\n",
      "10.813963680062443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8139636800624448"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_much_weight_lost(heavy_dictionary_list,tates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c522929-e2ea-4d52-927f-8253e897a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calories\n",
    "\n",
    "tates_calories = 140\n",
    "\n",
    "def remaining_calories(dictionary_list,list,target_calories):\n",
    "    new_equations = equations(dictionary_list,list,overall_dict)\n",
    "    calorie_count = (new_equations[4] * 4) + (new_equations[0] * 9) + (new_equations[7] * 4)\n",
    "    print(calorie_count)\n",
    "    return (target_calories / 2.8) - calorie_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1ceb9df-38b1-46c7-8775-3b9404b55308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.30507971533635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.3050797153363476"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_calories(heavy_dictionary_list,[0.4947484344244003, 0.19919266328215599, 0.13721138685941697, 0.10883750524371863, 0.06740383943542838, 0.07400253876112402],tates_calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eeca9751-7898-45dd-abd2-8ac7563de5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_left(vanilla_calories_per_1_gram,dictionary_list,list,tates_calories):\n",
    "    remaining_calories_val = remaining_calories(dictionary_list,list,tates_calories)\n",
    "    amount_vanilla = -remaining_calories_val / vanilla_calories_per_1_gram\n",
    "    return amount_vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58c525cc-53cc-4c9f-b167-82ede2a818f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.30507971533635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4500274880470164"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_left(2.9,heavy_dictionary_list,[0.4947484344244003, 0.19919266328215599, 0.13721138685941697, 0.10883750524371863, 0.06740383943542838, 0.07400253876112402],tates_calories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a824f1f9-cb3d-4fb5-a062-ef1715fd876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_calories_per_1_gram = 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590668a-a84b-4b0d-bf30-72ac702f82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#good things\n",
    "\n",
    "#got vanilla calories to come to around .45g (target is 5g)\n",
    "#doing the averages of the optimized\n",
    "\n",
    "#bad\n",
    "#chocolate totally over does the white + brown sugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d09bcc-4c74-4129-9a29-dada8d1f72fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2:\n",
    "\n",
    "\"\"\"from sklearn.linear_model import SGDRegressor\n",
    "\n",
    " sgd=SGDRegressor(learning_rate='constant',eta0=0.01)\n",
    "\n",
    " batch_size=15 #specifying the batch size\n",
    "\n",
    " for i in range(100):\n",
    "\n",
    "     indexes=random.sample(range(x_train.shape[0]),batch_size)\n",
    "\n",
    "     sgd.partial_fit(x_train[indexes],y_train[indexes])\n",
    "\n",
    " sgd.predict()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a6bd8-d001-4d4b-9ebb-11025f57d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3:\n",
    "\"\"\"import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from IPython.core.display import display, HTML\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbef56f-b122-4119-a02e-fd4f409f1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: try the git of medium article"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
