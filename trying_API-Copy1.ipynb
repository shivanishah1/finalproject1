{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f47c0971-a7ea-436a-a192-43e1b3ad69ba",
   "metadata": {},
   "source": [
    "things to think about:\n",
    "\n",
    "- water: right now the plan is to do the weight of the guessed ingredients (so calculating them without the weight in the equations function) and subtract the actual weight from this weight. \n",
    "- further idea:\n",
    "based on how the product was cooked, figure out what percent of each ingredient was cooked off for the final weight. Then looking at the difference, it should be the water weight + how much cooked off from the other ingredients. This gives us the water weight. If there was no cooking invovled --> this process isn't needed. Just calculate the ingredients and subtract the given weight from that weight to get the water weight.\n",
    "QUESTIONS:\n",
    "- write a function that looks at how many minimums the system of equations has. Isn't this on the simpler side? It's a matrix, right?\n",
    "        - how do we reduce the number of minima? \n",
    "             - include calories in the initial calculation? or include calories in initial initialization. How does calories work when baking? Does the item get to be less calories when baked? No, stays the same while weight decreases --> meaning we can use calories to measure as well!!!!!!!\n",
    "             - what else...\n",
    "Could we do something with the information of knowing how many possibilities there are? For example, we could use the number of ingredients and other properties (how nutritionally dense they are (how many are heavy), how many significant nutrient facts the product has, etc.) to set a confidence score. \n",
    "what exaactly are we doing with the onion method?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2250611-102e-43d8-9848-71a66711385d",
   "metadata": {},
   "source": [
    "A bunch of libraries to import. The first four are standard regular ones that I've worked with before. The next few are ones I'm getting to know as the project continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3ac28d-26f6-4ac2-9a8e-81667212816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 15:03:48.647410: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from functools import partial\n",
    "import requests #for the API"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb7920bd-cd06-436a-8ad3-7d358c02b9e7",
   "metadata": {},
   "source": [
    "creating the overall dictionary: the one representing the nutrition label facts. I will copy this dictionary for any ingredient I use."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab94ec58-ef19-4883-98a6-c882f91c7095",
   "metadata": {},
   "source": [
    "nutritional information for tates cookies per serving (28 grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1284dd2-f7c6-4dcf-bbe9-b74247e2c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dict = {}\n",
    "\n",
    "overall_dict[\"Total Fat\"] = 0\n",
    "overall_dict[\"Saturated Fat\"] = 0\n",
    "overall_dict[\"Trans Fat\"] = 0\n",
    "overall_dict[\"Cholesterol\"] = 0\n",
    "overall_dict[\"Sodium\"] = 0\n",
    "overall_dict[\"Total Carbs\"] = 0\n",
    "overall_dict[\"Fiber\"] = 0\n",
    "overall_dict[\"Total Sugar\"] = 0\n",
    "overall_dict[\"Protein\"] = 0\n",
    "overall_dict[\"Calcium\"] = 0\n",
    "overall_dict[\"Iron\"] = 0\n",
    "overall_dict[\"Potassium\"] = 0\n",
    "overall_dict[\"Vitamin D\"] = 0\n",
    "overall_dict[\"Water\"] = 0\n",
    "overall_dict[\"Weight\"] = 100\n",
    "overall_dict[\"Energy/Calories\"] = 0\n",
    "\n",
    "key_list_API = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Sodium', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Water', 'Weight', 'Energy/Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f647bf9-c62b-481b-a9f1-e694206ab906",
   "metadata": {},
   "outputs": [],
   "source": [
    "tates_dict = overall_dict.copy()\n",
    "tates_dict[\"Total Fat\"] = 7\n",
    "tates_dict[\"Saturated Fat\"] = 4.5\n",
    "tates_dict[\"Trans Fat\"] = 0\n",
    "tates_dict[\"Cholesterol\"] = .025\n",
    "tates_dict[\"Sodium\"] = .16\n",
    "tates_dict[\"Total Carbs\"] = 18\n",
    "tates_dict[\"Fiber\"] = .8\n",
    "tates_dict[\"Total Sugar\"] = 12\n",
    "tates_dict[\"Protein\"] = 2\n",
    "tates_dict[\"Calcium\"] = .0000001\n",
    "tates_dict[\"Iron\"] = .0009\n",
    "tates_dict[\"Potassium\"] = .01\n",
    "tates_dict[\"Vitamin D\"] = .05\n",
    "tates_dict[\"Weight\"] = 28\n",
    "tates_dict[\"Energy/Calories\"] = 140"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9358b96-8d68-4b37-af78-721711632612",
   "metadata": {},
   "source": [
    "dictionary for vanilla –– what does sugars entail? is there a way to include alcohol content through the sugars number? or \n",
    "is it better to do it through calories? Because if it was in sugars, then we could calculate the calories by multiplication (of 9)?\n",
    "the two below are dictionaries with the Alex-given more specific information."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f73d50e0-4832-41f9-ba49-b2db1a3733e3",
   "metadata": {},
   "source": [
    "need to check for multiple keys, ex. sugars total vs total, sugars. need to check energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb7f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_vanilla_dict = overall_dict.copy()\n",
    "#calories per 10 grams: 27 \n",
    "\n",
    "natural_vanilla_dict[\"Sodium\"] = .04 / 100\n",
    "natural_vanilla_dict[\"Total Carbs\"] = 12\n",
    "natural_vanilla_dict[\"Weight\"] = 100\n",
    "natural_vanilla_dict[\"Energy/Calories\"] = 270\n",
    "\n",
    "baking_soda_alex_dict = overall_dict.copy()\n",
    "#calories per 10 grams: 0\n",
    "\n",
    "baking_soda_alex_dict[\"Sodium\"] = 27.36\n",
    "baking_soda_alex_dict[\"Weight\"] = 100"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16d5f14f-c12e-4499-97d7-42520c4d28ff",
   "metadata": {},
   "source": [
    "reading in the information through USDA API: requested key : pJdDYwC0EdXMpR18wMXFqjMxO4zYGCuTOfNfCSH4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "841c36e8-86ca-4f2f-91a3-7292ca460459",
   "metadata": {},
   "source": [
    "how to know which type of food? foundational? Now need to create a dictionary that stores which fdcID 's we are using?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0f3dd1-384c-4502-802f-2a090b3b6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_conversion(nutrient_name,dict,amount,unit):\n",
    "    if unit == \"kJ\":\n",
    "        dict[nutrient_name] = (amount/4.184)\n",
    "    elif unit == \"mg\":\n",
    "        dict[nutrient_name] = (amount/1000)\n",
    "    elif unit == \"µg\":\n",
    "        dict[nutrient_name] = (amount/ 1000000)\n",
    "    else:\n",
    "        dict[nutrient_name] = (amount)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7857edf6-2095-44b0-923e-d139649479b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fats = [\"Total lipid (fat)\"]\n",
    "saturated_fats = [\"Saturated fatty acids\",\"Fatty acids, total saturated\"]\n",
    "trans_fat = [\"Fatty acids, total trans\"]\n",
    "cholesterol = [\"Cholesterol\"]\n",
    "sodium = [\"Sodium, Na\"]\n",
    "total_carbs = [\"Carbohydrate, by difference\"]\n",
    "fiber = [\"Fiber\",\"Fiber, total dietary\"]\n",
    "total_sugar = [\"Sugars, Total\",\"Total Sugars\",\"Total Sugar\",\"Sugars, added\"]\n",
    "protein = [\"Protein\"]\n",
    "calcium = [\"Calcium, Ca\"]\n",
    "iron = [\"Iron, Fe\"]\n",
    "potassium = [\"Potassium, K\"]\n",
    "vitamin_D = [\"Vitamin D (D2 + D3)\"]\n",
    "weight = [\"Weight\"]\n",
    "energy_calories = [\"Energy\"] \n",
    "\n",
    "def super_big_function(dict,amount,nutrient_name,unit):\n",
    "    if nutrient_name in total_fats:\n",
    "        unit_conversion(\"Total Fat\",dict,amount,unit)\n",
    "    elif nutrient_name in saturated_fats:\n",
    "        unit_conversion(\"Saturated Fat\",dict,amount,unit)\n",
    "    elif nutrient_name in trans_fat:\n",
    "        unit_conversion(\"Trans Fat\",dict,amount,unit)\n",
    "    elif nutrient_name in cholesterol:\n",
    "        unit_conversion(\"Cholesterol\",dict,amount,unit)   \n",
    "    elif nutrient_name in sodium:\n",
    "        unit_conversion(\"Sodium\",dict,amount,unit)\n",
    "    elif nutrient_name in total_carbs:\n",
    "        unit_conversion(\"Total Carbs\",dict,amount,unit)\n",
    "    elif nutrient_name in fiber:\n",
    "        unit_conversion(\"Fiber\",dict,amount,unit)\n",
    "    elif nutrient_name in total_sugar:\n",
    "        unit_conversion(\"Total Sugar\",dict,amount,unit)  \n",
    "    elif nutrient_name in protein:\n",
    "        unit_conversion(\"Protein\",dict,amount,unit)\n",
    "    elif nutrient_name in calcium:\n",
    "        unit_conversion(\"Calcium\",dict,amount,unit)\n",
    "    elif nutrient_name in iron:\n",
    "        unit_conversion(\"Iron\",dict,amount,unit)\n",
    "    elif nutrient_name in potassium:\n",
    "        unit_conversion(\"Potassium\",dict,amount,unit)   \n",
    "    elif nutrient_name in vitamin_D:\n",
    "        unit_conversion(\"Vitamin D\",dict,amount,unit)\n",
    "    elif nutrient_name in weight:\n",
    "        unit_conversion(\"Weight\",dict,amount,unit)\n",
    "    elif nutrient_name in energy_calories:\n",
    "        unit_conversion(\"Energy/Calories\",dict,amount,unit)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5800e46-7f82-4b00-8581-5d39047c84ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb6d87e-dcd8-46cd-aa9d-f252192ed831",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_key_list = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Sodium', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Water', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39587d4-cd7d-4b74-bcb4-818c77cfe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"pJdDYwC0EdXMpR18wMXFqjMxO4zYGCuTOfNfCSH4\"\n",
    "\n",
    "def getting_from_API(query):\n",
    "    food_words = query.split()\n",
    "    url = f\"https://api.nal.usda.gov/fdc/v1/foods/search?query={query}&dataType=Foundation&api_key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    for individual_food_dict in data['foods'][:5]:\n",
    "        match = 0\n",
    "        individual_food = individual_food_dict[\"description\"].lower()\n",
    "        individual_words_list = re.split(r\"[,\\s]+\", individual_food)\n",
    "        #individual_words_list = individual_food.split()\n",
    "        \n",
    "        for word in food_words:\n",
    "            if word not in individual_words_list:\n",
    "                match = match - 1\n",
    "            else:\n",
    "                match = match + 1\n",
    "        if match == len(food_words):\n",
    "            return individual_food_dict['fdcId']\n",
    "    url = f\"https://api.nal.usda.gov/fdc/v1/foods/search?query={query}&dataType=Branded&api_key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    for individual_food_dict in data['foods'][:5]:\n",
    "        match = 0\n",
    "        individual_food = individual_food_dict[\"description\"].lower()\n",
    "        individual_words_list = re.split(r\"[,\\s]+\", individual_food)\n",
    "        for word in food_words:\n",
    "            if word not in individual_words_list:\n",
    "                match = match - 1\n",
    "            else:\n",
    "                match = match + 1\n",
    "        if match == len(food_words):\n",
    "            return individual_food_dict['fdcId']       \n",
    "    \n",
    "    return \"ERROR NOTHING IS A MATCH :(((((\"\n",
    "\n",
    "def opening_API(fdc_id,dict):\n",
    "    \n",
    "    nutrition_url = f\"https://api.nal.usda.gov/fdc/v1/food/{fdc_id}?api_key={api_key}\"\n",
    "\n",
    "    response = requests.get(nutrition_url)\n",
    "    nutrition_data = response.json()\n",
    "\n",
    "    for nutrient in nutrition_data['foodNutrients']:\n",
    "        nutrient_name = nutrient['nutrient']['name']\n",
    "        amount = nutrient.get(\"amount\",\"NA\")\n",
    "        unit = nutrient.get(\"nutrient\", {}).get(\"unitName\", \"\")\n",
    "        super_big_function(dict,amount,nutrient_name,unit)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436df81f-9ab7-41f3-82d3-b285dcf64194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getting_from_API(\"semi-sweet chocolate\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12c2432f-e5bd-4b31-a1b0-c0f55e28ad09",
   "metadata": {},
   "source": [
    "the various ingredients in Tate's. Transforming the online nutritional information of each ingredient into individual dictionaries.\n",
    "\n",
    "- CHECK INNGREDIENTS OF USDA : semi sweet chooclate alligns w tates semi sweet chocolate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1058471-cc4e-4910-a56e-d9a8c3fd7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"semi-sweet chocolate\",\"unbleached flour\",\"salted butter\",\"cane sugar\",\"brown cane sugar\",\"egg whole\",\"salt\"]\n",
    "\n",
    "def product_dicts(queries):\n",
    "    dicts = {}\n",
    "    for query in queries:\n",
    "        fdc_id = getting_from_API(query)\n",
    "        print(fdc_id)\n",
    "        new_dict = overall_dict.copy()\n",
    "        opening_API(fdc_id,new_dict)\n",
    "        dicts[query] = new_dict\n",
    "        print(\"added\")\n",
    "    return dicts\n",
    "\n",
    "\n",
    "#semi_sweet_chocolate_dict = overall_dict.copy()\n",
    "#fdc_id_semi_sweet_chocolate = getting_from_API(\"semi sweet chocolate\")\n",
    "#opening_API(fdc_id_semi_sweet_chocolate,semi_sweet_chocolate_dict)\n",
    "\n",
    "#dictionary_list = [semi_sweet_chocolate_dict,unbleached_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict,baking_soda_alex_dict,salt_dict,natural_vanilla_dict]\n",
    "#heavy_dictionary_list = [semi_sweet_chocolate_dict,unbleached_flour_dict,salted_butter_dict,cane_sugar_dict,brown_cane_sugar_dict,eggs_dict]\n",
    "#key_list = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Sodium\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\",\"Weight\",\"Calories\"]\n",
    "#key_list_wo_weight = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Sodium\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\",\"Calories\"]\n",
    "#key_list_wo_sodium_and_weight = [\"Fat\",\"Saturated fatty acids\",\"Fatty acids, total trans\",\"Cholesterol\",\"Carbohydrate\",\"Fiber\",\"Sugars\",\"Protein\",\"Calcium\",\"Iron\",\"Potassium\",\"Vitamin D\",\"Calories\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c532bde4-9e1d-47a4-8af8-0f076106a939",
   "metadata": {},
   "source": [
    "so now, have a dict with tates ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c33378a-e1b0-44a6-a638-0d8ae5b02bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012567\n",
      "added\n",
      "1104913\n",
      "added\n",
      "790508\n",
      "added\n",
      "1882741\n",
      "added\n",
      "2015023\n",
      "added\n",
      "748967\n",
      "added\n",
      "746775\n",
      "added\n"
     ]
    }
   ],
   "source": [
    "tates_ingredient_dict = product_dicts(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8502531b-500b-41bb-a101-3e2577dd2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semi-sweet chocolate', 'unbleached flour', 'salted butter', 'cane sugar', 'brown cane sugar', 'egg whole', 'salt']\n",
      "['semi-sweet chocolate', 'unbleached flour', 'salted butter', 'cane sugar', 'brown cane sugar', 'egg whole']\n",
      "['semi-sweet chocolate', 'unbleached flour', 'salted butter', 'cane sugar', 'brown cane sugar', 'egg whole', 'baking soda', 'salt', 'vanilla extract']\n"
     ]
    }
   ],
   "source": [
    "tates_ingredient_dict[\"baking soda\"] = baking_soda_alex_dict\n",
    "tates_ingredient_dict[\"vanilla extract\"] = natural_vanilla_dict\n",
    "tates_ingredient_dict[\"salted butter\"][\"Energy/Calories\"] = 714\n",
    "ingredients = queries[:-1]\n",
    "print(queries)\n",
    "print(ingredients)\n",
    "ingredients.append(\"baking soda\")\n",
    "ingredients.append(\"salt\")\n",
    "ingredients.append(\"vanilla extract\")\n",
    "print(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07a2af5e-0a8f-4b65-a502-840ba55f4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['semi-sweet chocolate', 'unbleached flour', 'salted butter', 'cane sugar', 'brown cane sugar', 'egg whole']\n"
     ]
    }
   ],
   "source": [
    "heavy_ingredients = ingredients[:-3]\n",
    "print(heavy_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635be9c7-5981-4067-a050-919369cfd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_x_list(number,dictionary_list):\n",
    "    x_list = []\n",
    "    for variable in range(0, len(dictionary_list)):\n",
    "        x_list.append(number)\n",
    "    return x_list\n",
    "\n",
    "x_list = building_x_list(1,ingredients)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e5ec123-1e93-4f6d-b2a0-318b24540711",
   "metadata": {},
   "source": [
    "function that evaluates the guesses and compares them with the goal values (nutritonal info for target product). Divided by 100 when evaluating because each dictionary is out of 100 grams. So if I had 200 grams of eggs, I'd multiply each nutritional fact by 2 (as each fact is per 100 grams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71dd96b6-b1f4-4153-aca4-22ec74dd5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equations(product_dictionaries,ingredients,x_list,desired_dict,key_list):\n",
    "    list_of_equations = []\n",
    "    for key in key_list:\n",
    "        equation = 0\n",
    "        for i,ingredient in enumerate(ingredients):\n",
    "            equation = equation + (product_dictionaries[ingredient][key] * (x_list[i] / 100))\n",
    "        list_of_equations.append(equation-(desired_dict[key]))\n",
    "        #so if something iss negative, tates > val, if positive, val > tates. so we only want negative!\n",
    "    return list_of_equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90693b07-063d-416d-a780-6145ad5218da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6160736322879785,\n",
       " -0.36973636894226125,\n",
       " 0.0,\n",
       " -0.0033023502933979057,\n",
       " 0.07625149765014427,\n",
       " -0.32515838432312016,\n",
       " 0.4589569746494284,\n",
       " -0.9965880723953249,\n",
       " 0.0032110334133148197,\n",
       " -0.0004691434089303016,\n",
       " 0.0027104968500137328,\n",
       " -0.049999933759455134,\n",
       " 0.0,\n",
       " -0.06572284098336922]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equations(tates_ingredient_dict,heavy_ingredients,trial,tates_dict,heavy_key_list_no_weight)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc5e9518-9e92-4271-8cd1-46702795ce2e",
   "metadata": {},
   "source": [
    "initializes variables, choosing random numbers between 0 and the largest weight possible. The variables all together should add up to the final weight. So first, I create these values. Then sort them in descending order. Then divide by a normalizing factor to ensure they add up to the final weight. This factor is just the weight / sum of variables.\n",
    "\n",
    "Just added: Ensure the first variable is within a given range of ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a9a79a-8b3c-45bf-af72-8f3462bd4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables_tf(n,desired_dict,first_ratio_range):\n",
    "    #first_ratio_range is a tuple, low and high ends of \n",
    "    largest_weight = desired_dict[\"Weight\"]\n",
    "    first_variable_weight = 0\n",
    "    other_weight_for_first_ratio = largest_weight\n",
    "    lower_bound, upper_bound = first_ratio_range\n",
    "    #this is for ex. cho chips are 80 percent of dough instead of cho chips are 80 percent of the whole weight\n",
    "    first_ratio = first_variable_weight / other_weight_for_first_ratio\n",
    "\n",
    "    while (first_ratio < lower_bound) or (first_ratio > upper_bound):\n",
    "        initial_values = tf.random.uniform(shape=(n,), minval=0.0, maxval=largest_weight)\n",
    "        initial_values = tf.sort(initial_values, direction='DESCENDING')\n",
    "\n",
    "        initial_values = (initial_values * largest_weight) / tf.reduce_sum(initial_values)\n",
    "        first_variable_weight = initial_values[0]\n",
    "        other_weight_for_first_ratio = tf.reduce_sum(initial_values[1:])\n",
    "        first_ratio = first_variable_weight / other_weight_for_first_ratio\n",
    "\n",
    "    return tf.Variable(initial_values, trainable=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87edc75d-c7a6-477c-8fc7-54782abd385f",
   "metadata": {},
   "source": [
    "this is the loss function. need to update this to provide more info.\n",
    "what can I add?\n",
    "- parameters: all variables are > 0, in descending order, equations --> 0\n",
    "- initialize first variable using ratios. LOOK AT THIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c2c77b-f00b-4971-a70b-0eee2acc166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tf(variables_tf,predicted):\n",
    "\n",
    "    error = tf.reduce_mean(tf.square(predicted))\n",
    "    error = error +  5*(tf.reduce_sum(tf.square(tf.minimum(variables_tf, 0))))\n",
    "    \n",
    "    variables_tf_array = variables_tf.numpy()\n",
    "    for i in range(0,len(variables_tf_array)-2):\n",
    "        if variables_tf_array[i] - variables_tf_array[i + 1] < 0:\n",
    "            error = error + ((variables_tf_array[i] - variables_tf_array[i + 1]) ** 2)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2493d7d6-f1db-430c-91f9-12946c9bc1e8",
   "metadata": {},
   "source": [
    "now this is the training loop."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f27ebe8-c7b6-4a0c-b329-53704c901e6e",
   "metadata": {},
   "source": [
    "could we change the learning rate as we go on? like the first few have a certain learning rate then we change it? interesting...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25e92179-5f5f-41c8-bb75-88c859639ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to ensure returns either negative or 0 error? how to penalize for positive?\n",
    "\n",
    "def running_tf(product_dictionaries,ingredients,desired_dict,key_list,ratio_range,print=False):  \n",
    "    #number of ingredients\n",
    "    n = len(ingredients)\n",
    "    #first guess\n",
    "    variables_tf = initialize_variables_tf(n,desired_dict,ratio_range)\n",
    "    #the optimizer chosen: stochastic gradient descent. WHAT IF WE TRIED batch gradient descent here?\n",
    "    #pros/cons: https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/\n",
    "    #whats the math behind this?\n",
    "        #updates each variable. the variable is updated to be its value - \n",
    "        #the learning rate * the gradient of how much that variable affects the loss.\n",
    "        #THIS PART IS DIFFERENT FROM MY PREVIOUS METHOD MATHEMATICALLY, but does the same thing\n",
    "        #SHOW tests for learning rates. date the comments.\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=.01)\n",
    "\n",
    "# Training loop\n",
    "    #redefines the variable 600 times. what number is OPTIMAL?\n",
    "    for epoch in range(400):\n",
    "\n",
    "        #the \"with\" allows for automatic differentiation. this means the with part locks in the operations. but here no gradients are calculated.\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            predictions1 = equations(product_dictionaries,ingredients,variables_tf,desired_dict,key_list)\n",
    "            predictions = tf.convert_to_tensor(predictions1)\n",
    "            loss = loss_tf(variables_tf,predictions)\n",
    "\n",
    "        #gradients are computed here.\n",
    "        gradients = tape.gradient(loss, [variables_tf])\n",
    "\n",
    "        #apply these gradients, perform sgd on our variables (which are being updated) \n",
    "        optimizer.apply_gradients(zip(gradients, [variables_tf]))\n",
    "\n",
    "        predictions_updated = equations(product_dictionaries, ingredients, variables_tf, desired_dict, key_list)\n",
    "        new_loss = loss_tf(variables_tf, tf.convert_to_tensor(predictions_updated))\n",
    "\n",
    "        if print == True and epoch % 20 == 0:\n",
    "            print((tf.reduce_sum(variables_tf).numpy()))\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}, New Loss: {new_loss.numpy():.4f}, Variables: {variables_tf.numpy()}\")\n",
    "\n",
    "        if new_loss > loss:\n",
    "            return (loss,variables_tf.numpy().tolist())\n",
    "            \n",
    "    return (loss,variables_tf.numpy().tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "393aeb5a-baa6-407b-a09a-cda34ba46670",
   "metadata": {},
   "source": [
    "look at epochs. convergence rate? 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824e6ddd-ae7d-48c3-adfe-0d8162e06ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_key_list = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Water', 'Weight', 'Energy/Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49451d31-f1a5-435d-bfec-0c103850c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_key_list_no_weight = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Water', 'Energy/Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f42f9d-9b0d-4edc-b30a-d5a7a6efb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_key_list_no_weight_or_cal = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15d6c8e8-ce74-4d08-aa42-ee8398095efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list_no_weight = ['Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol', 'Sodium', 'Total Carbs', 'Fiber', 'Total Sugar', 'Protein', 'Calcium', 'Iron', 'Potassium', 'Vitamin D', 'Energy/Calories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fc1dc03-50df-44dc-bdfd-38b6ef133649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.1413825>,\n",
       " [6.597270965576172,\n",
       "  6.529214382171631,\n",
       "  5.8894124031066895,\n",
       "  5.591473579406738,\n",
       "  3.426011085510254,\n",
       "  0.3141237795352936])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_tf(tates_ingredient_dict,heavy_ingredients,tates_dict,new_key_list,(.25,.45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1286ca4d-6be9-43f6-b34a-30dbac01cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_tfs(product_dictionaries,ingredients,desired_dict,key_list,ratio_range,number_of_times_run):\n",
    "    lowest_loss = 500\n",
    "    lowest_resulting_list = []\n",
    "    for i in range(0,number_of_times_run):\n",
    "        loss, resulting_list = running_tf(product_dictionaries,ingredients,desired_dict,key_list,ratio_range)\n",
    "        if loss < lowest_loss:\n",
    "            lowest_loss = loss\n",
    "            lowest_resulting_list = resulting_list\n",
    "    return (lowest_loss,lowest_resulting_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2b4598b-6945-4c7f-bd02-af101dab0e76",
   "metadata": {},
   "source": [
    "multiple_tfs(tates_ingredient_dict,heavy_ingredients,tates_dict,key_list_API,(.2,.3),10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7518317-6969-447e-9594-7491b462f95f",
   "metadata": {},
   "source": [
    "need to make some sort of journal / tracker to record values with varaying inputs.\n",
    "- where to do this? excel?: https://docs.google.com/spreadsheets/d/1JaqNnqDaNqFfK0VauvhND7xTFVfdoKkRyTLoEnHcdUI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "782898d0-56c8-4b74-a203-a8438afa6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial =  [6.687910079956055,\n",
    "  6.379572868347168,\n",
    "  6.321332931518555,\n",
    "  5.336599349975586,\n",
    "  4.272467613220215,\n",
    "  1.6648460626602173]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "378f4182-74c6-464b-a416-72b18388c550",
   "metadata": {},
   "source": [
    "issue: there are way too many local minimum. How do I find the one I want? \n",
    "- I could present all my local minimum possibilities... how to pick the certain one?\n",
    "- do I calculate a bunch and choose the one with lowest loss? Do I calculate and then find the most recurring one? This one appears the most naturally?\n",
    "- how can I incorporate food science ideas? Maybe I can add relationships between the ingredients. so if a food has more than a few sugar-contributing ingredients, etc... what to do with that?\n",
    "- could I pass each guess through a \"viable food product\" type of function?\n",
    "    - processing-aware constraints, so there must be a specific flour to fat ratio for proper dough structure. or high sugar/fat ratio could cause spreading in cookies, etc. if something is very off the ratio?\n",
    "    - is there a way we could train the model with existing cookie recipes so that it can understand ratios? How do you even do this? once it understands ratios of other recipes, then when looking at all the possibilities it outputted, it can choose which one makes the most sense.\n",
    "    - put the guess through AI and have it say if its viable?\n",
    "    - make custom GPT for ratio detection from past recipes & online research & books\n",
    "    - maybe after each iteration, ask questions like\n",
    "        - does it have enough liquid? (ex. w the tates cookies, if it doesn't, then increase the eggs --> decrease the chocolate chips --> increase white/brown sugar). \n",
    "        - how would we know how much liquid it needs? maybe someone would input the recipe along with tags: - how dry, how crumbly, how many chocolate chips it seemingly has, etc. But isn't this similar to using the sensory analysis? Or isn't this just giving a helping hand. For example, if someone says this cookie has medium chocolate chips, then we restraint our chocolate chip guess to a specific ratio of the dough. \n",
    "            - what if someone inputted the nutritional label + possible dominating ingredients? That way if there are no dominating ingredients, we want the ratios of each one to follow some sort of pattern/curve. But if there is a dominating ingredient (ex. water in a water-based beverage) then we make an exception. so no dominating means if the product has multiple ingredients that contribute to the same nutrient, ensuring that one doesn't hog all of it (assuming these are all heavier ingredients)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "feb0d3d9-669c-4e06-b5ff-0ba239f61c94",
   "metadata": {},
   "source": [
    "after optimizing the heavy ingredients, add noise to the list to make room for lighter ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ffb859c-6f46-47b1-8a9c-ee4a176d687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(optimized_heavy_ingredients):\n",
    "    optimized_w_noise = []\n",
    "    for i in range(0,len(optimized_heavy_ingredients)):\n",
    "        number = random.randint(1,2)\n",
    "        if number == 1:\n",
    "            optimized_w_noise.append(optimized_heavy_ingredients[i] - .1)\n",
    "        else:\n",
    "            optimized_w_noise.append(optimized_heavy_ingredients[i] + .1)\n",
    "    return optimized_w_noise"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b05c6534-ae69-4109-9939-edbb61b2f747",
   "metadata": {},
   "source": [
    "error function for combined heavier + lighter ingredients. This looks at how the \"equations\" function evaluates as well as the calories. WOULD IT BE SMARTER TO MOVE THE CALORIES PORTION? Also, look at the 100 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d9aae-e87c-460b-8258-a993096fdf26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "49984466-af10-48dd-9f38-36966abaa27b",
   "metadata": {},
   "source": [
    "def error_function_lighter1(lighter_ingredients,optimized_heavy_ingredients):\n",
    "\n",
    "    full_ingredients = np.concatenate((optimized_heavy_ingredients, lighter_ingredients))\n",
    "\n",
    "    equations_list = equations(tates_ingredient_dict,ingredients,full_ingredients,tates_dict,heavy_key_list_no_weight)\n",
    "    error = 0\n",
    "    for i, equation in enumerate(equations_list):\n",
    "        #if i == 4 or i == 5:\n",
    "        #    error += equation ** 2\n",
    "        #else:\n",
    "        #THIS IS TO GIVE MORE WEIGHT TO A CERTAIN NUTRITIONAL INGREDIENT\n",
    "        error += equation\n",
    "\n",
    "    #dividing by 100 here because otherwise the error is too high - leaves bayesian optimization to just choose lowest option for lightest ingredients\n",
    "    #error += (difference_in_calories / 10)   \n",
    "    return abs(error)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85b8c4bd-62e1-429f-a60f-9a9978a48d5c",
   "metadata": {},
   "source": [
    "def error_function_lighter2(lighter_ingredients,optimized_heavy_ingredients):\n",
    "\n",
    "    full_ingredients = np.concatenate((np.array(optimized_heavy_ingredients), np.array(lighter_ingredients)))\n",
    "\n",
    "    equations_list = equations(tates_ingredient_dict,ingredients,full_ingredients,tates_dict,key_list_no_weight)\n",
    "    error = 100 * (equations_list[4] ** 2)\n",
    "    for i in range(1,3):\n",
    "        if full_ingredients[-i] - full_ingredients[-i - 1] > 0:\n",
    "            error = error + ((full_ingredients[-i] - full_ingredients[-i - 1]) ** 2)\n",
    "\n",
    "    equations_list = np.array(equations_list, dtype=np.float64)\n",
    "\n",
    "\n",
    "    error = tf.reduce_mean(tf.square(equations_list))\n",
    "\n",
    "    \n",
    "\n",
    "    return float(error.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d2afd099-8189-42e0-be49-c10f48cc53f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_dictionary={}\n",
    "\n",
    "\n",
    "def fixed_heavy_dictionary(optimized_heavy_ingredients,key_list_initial, key_list_final):\n",
    "\n",
    "    x_list = building_x_list(1,heavy_ingredients)\n",
    "\n",
    "    error_for_optimized = equations(tates_ingredient_dict,heavy_ingredients,optimized_heavy_ingredients,tates_dict,key_list_initial)\n",
    "    print(sum(error_for_optimized))\n",
    "\n",
    "    #evaluate on initial key list, but return all keys. So this means then evaluating the keys that weren't included in the initial key_list\n",
    "    \n",
    "    for i in range(0,len(key_list_final)):\n",
    "        key = key_list[i]\n",
    "        print(key)\n",
    "        error_at_this_key = error_for_optimized[i]\n",
    "        optimized_dictionary[key] = error_at_this_key\n",
    "\n",
    "    return optimized_dictionary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "992610d4-5bcf-4b72-8574-c21f0682305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "triall =   [6.597270965576172,\n",
    "  6.529214382171631,\n",
    "  5.8894124031066895,\n",
    "  5.591473579406738,\n",
    "  3.426011085510254,\n",
    "  0.3141237795352936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a76e38db-4ad5-4e47-a044-afebc71e8e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Total Fat': 0.6160736322879785,\n",
       " 'Saturated Fat': -0.36973636894226125,\n",
       " 'Trans Fat': 0.0,\n",
       " 'Cholesterol': -0.0033023502933979057,\n",
       " 'Sodium': -0.12201583836913109,\n",
       " 'Total Carbs': 0.07625149765014427,\n",
       " 'Fiber': -0.32515838432312016,\n",
       " 'Total Sugar': 0.4589569746494284,\n",
       " 'Protein': -0.9965880723953249,\n",
       " 'Calcium': 0.0032110334133148197,\n",
       " 'Iron': -0.0004691434089303016,\n",
       " 'Potassium': 0.0027104968500137328,\n",
       " 'Vitamin D': -0.049999933759455134,\n",
       " 'Water': 0.0,\n",
       " 'Weight': 2.6627289056777954,\n",
       " 'Energy/Calories': -0.06572284098336922}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_heavy_dictionary(trial,key_list_API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6b6ecbd5-6456-4e70-a011-2763e94f1226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.287294713701527\n",
      "Total Fat\n",
      "Saturated Fat\n",
      "Trans Fat\n",
      "Cholesterol\n",
      "Sodium\n",
      "Total Carbs\n",
      "Fiber\n",
      "Total Sugar\n",
      "Protein\n",
      "Calcium\n",
      "Iron\n",
      "Potassium\n",
      "Vitamin D\n",
      "Water\n",
      "Weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Total Fat': 0.0998257279992103,\n",
       " 'Saturated Fat': -0.6261033887863157,\n",
       " 'Trans Fat': 0.0,\n",
       " 'Cholesterol': -0.009868832118809227,\n",
       " 'Sodium': -0.12654484031528235,\n",
       " 'Total Carbs': -0.3619944262504582,\n",
       " 'Fiber': -0.3315937614440919,\n",
       " 'Total Sugar': -0.07734439848661445,\n",
       " 'Protein': -1.1542198194265367,\n",
       " 'Calcium': 0.002497422463798523,\n",
       " 'Iron': -0.0004953165926843882,\n",
       " 'Potassium': 0.0010406926643848399,\n",
       " 'Vitamin D': -0.04999996871490541,\n",
       " 'Water': 0.0,\n",
       " 'Weight': 0.34750619530677795}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_heavy_dictionary(triall,new_key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6a44a40-ba4c-46c9-9d07-c3d88031173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_for_light_fixing_heavy(light_ingredients,optimized_heavy_ingredients):\n",
    "\n",
    "    desired_dict = fixed_heavy_dictionary(optimized_heavy_ingredients,key_list_API)\n",
    "\n",
    "    equations_list = equations(tates_ingredient_dict,ingredients[-3:],light_ingredients,desired_dict,key_list_no_weight)\n",
    "    \n",
    "    error = 100 * (equations_list[4] ** 2)\n",
    "\n",
    "    #see if I need this, or how much weight this is given to error\n",
    "    for i in range(1,3):\n",
    "        if light_ingredients[-i] - light_ingredients[-i - 1] > 0:\n",
    "            error = error + ((light_ingredients[-i] - light_ingredients[-i - 1]) ** 2)\n",
    "\n",
    "    #equations_list = np.array(equations_list, dtype=np.float64)\n",
    "\n",
    "\n",
    "    #error = tf.reduce_mean(tf.square(equations_list))\n",
    "    error += sum(equations_list)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1314b5e7-5d3d-4d4c-8413-a51ff153b2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2645757789163024"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_for_light_fixing_heavy([.0,.0,.0],trial)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0a5ee62-fb09-4543-b67c-74c139c8ee61",
   "metadata": {},
   "source": [
    "Bayesian occurance. Samples points + finds the points that contribute to the least error. \n",
    "\n",
    "There is so much to play around with here\n",
    "- the error function. this basically dictates everything. The bayesian function tries (# of points we tell it to) and finds the best match.  this best match is entirely decided by the error function. Here, the error function is error_function_lighter. What to include and not include in this function to make it the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b617dee6-966d-48db-a23b-b424a921f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map lighter ingredients to their indices\n",
    "lighter_indices = [6, 7, 8]  # vanilla, baking soda, xanthan gum\n",
    "\n",
    "# Define the search space for Bayesian Optimization using the indices\n",
    "search_space = [\n",
    "    Real(0.0000001, 1, name=f\"ingredient_{lighter_indices[0]}\"),  # baking_soda\n",
    "    Real(0.0000001, 1, name=f\"ingredient_{lighter_indices[1]}\"),  # salt\n",
    "    Real(0.0000001, 1, name=f\"ingredient_{lighter_indices[2]}\")   # vanilla\n",
    "]\n",
    "\n",
    "def bayesiann(optimized_heavy_ingredients):\n",
    "    print(\"Optimized heavy ingredients passed to bayesiann:\")\n",
    "    print(optimized_heavy_ingredients)\n",
    "\n",
    "    error_function_fixed = partial(error_for_light_fixing_heavy, optimized_heavy_ingredients=optimized_heavy_ingredients)\n",
    "\n",
    "    result = gp_minimize(\n",
    "    func=error_function_fixed,  # Pass the function to minimize\n",
    "    dimensions=search_space,\n",
    "    n_calls=100,\n",
    "    n_random_starts=10,\n",
    "    random_state=410  # Uncomment for reproducibility\n",
    ")\n",
    "    print(\"Trial History (Guessed Inputs and Corresponding Losses):\")\n",
    "    for i, (inputs, loss) in enumerate(zip(result.x_iters, result.func_vals)):\n",
    "        print(f\"Trial {i+1}: Inputs = {inputs}, Loss = {loss}\")\n",
    "\n",
    "    optimized_lighter_ingredients = result.x\n",
    "    print(\"Debug: Optimized lighter ingredients from Bayesian Optimization:\")\n",
    "    print(result.x)\n",
    "\n",
    "    print(\"Debug: Minimum error achieved:\")\n",
    "    print(result.fun)\n",
    "    return optimized_lighter_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0cf20bfb-2a9d-4f5d-98df-b689ddc5d40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized heavy ingredients passed to bayesiann:\n",
      "[6.687910079956055, 6.379572868347168, 6.321332931518555, 5.336599349975586, 4.272467613220215, 1.6648460626602173]\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.2166229906357163, 0.15783411441752448, 0.751873798807828]\n",
      "  warnings.warn(\n",
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.5743838814292236, 0.14819688556044272, 0.48903172923317806]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.6159393223971137, 0.5311106834427753, 0.8091473100908627]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.13819305083328481, 0.059413726671020066, 0.03395131611394538]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.3282240821270189, 0.11288377338844444, 0.6140014265620749]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.8645733179440824, 0.4427562582912875, 0.32418309635576886]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.2765559692511487, 0.21622482898079362, 0.19780383800630963]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.026944143183216314, 0.4227721100926157, 0.3855865756904617]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.6342417611893675, 0.12994526527580735, 0.8890156467215342]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "1.8869396080536853\n",
      "1.8869396080536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1e-07] before, using random point [0.9050339030786307, 0.8731462280539649, 0.15200171699304788]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8869396080536853\n",
      "Trial History (Guessed Inputs and Corresponding Losses):\n",
      "Trial 1: Inputs = [0.5574396817667324, 0.5279668591641179, 0.8561068083898229], Loss = 26.585295079135363\n",
      "Trial 2: Inputs = [0.7539295569749173, 0.03886934215416717, 0.013633090209335936], Loss = 12.823358580136874\n",
      "Trial 3: Inputs = [0.4633875429059946, 0.5998915348310422, 0.08766771214737554], Loss = 24.53286662597847\n",
      "Trial 4: Inputs = [0.5338848704456247, 0.22192046354122805, 0.7596315432253532], Loss = 15.96884426101283\n",
      "Trial 5: Inputs = [0.6321626748377455, 0.4943105625354395, 0.09026948893971057], Loss = 25.041114099783375\n",
      "Trial 6: Inputs = [0.8445672333479876, 0.23231749941448326, 0.01668420804724873], Loss = 20.76851870149849\n",
      "Trial 7: Inputs = [0.7059847559792597, 0.09417683337930893, 0.47352110779145984], Loss = 14.848450321852377\n",
      "Trial 8: Inputs = [0.8488952284938576, 0.883370282414654, 0.604652899095959], Loss = 51.51781325366062\n",
      "Trial 9: Inputs = [0.01724983185009452, 0.607989941634221, 0.03580685495567434], Loss = 14.57246789515439\n",
      "Trial 10: Inputs = [0.7292730386998901, 0.03126578242225793, 0.9314106035325191], Loss = 15.556410680222342\n",
      "Trial 11: Inputs = [1e-07, 1e-07, 1e-07], Loss = 2.2645777391121564\n",
      "Trial 12: Inputs = [0.2166229906357163, 0.15783411441752448, 0.751873798807828], Loss = 9.24365008617567\n",
      "Trial 13: Inputs = [0.5743838814292236, 0.14819688556044272, 0.48903172923317806], Loss = 13.810276363716909\n",
      "Trial 14: Inputs = [0.14940351582400033, 0.007064766469523809, 0.00755749143744386], Loss = 3.583937776436603\n",
      "Trial 15: Inputs = [0.011971377402438544, 0.06707566787207961, 0.00939905930864882], Loss = 3.1222416777396482\n",
      "Trial 16: Inputs = [0.6159393223971137, 0.5311106834427753, 0.8091473100908627], Loss = 28.118756843023533\n",
      "Trial 17: Inputs = [0.00750743586144951, 0.0003223392732233501, 0.3749051378359773], Loss = 3.517982072459662\n",
      "Trial 18: Inputs = [0.005977935022499197, 0.009737492590031658, 0.05264196988092704], Loss = 2.55509001808961\n",
      "Trial 19: Inputs = [0.011595598278760787, 0.9987458410237977, 0.8236249559428872], Loss = 30.6474238310062\n",
      "Trial 20: Inputs = [0.015032415610962907, 0.012247635211923225, 0.9631545715458933], Loss = 6.117730486199447\n",
      "Trial 21: Inputs = [0.0049797572678858554, 0.07211664585365911, 0.0564086783864648], Loss = 3.257474297207231\n",
      "Trial 22: Inputs = [0.02688652046748635, 0.024972840197059764, 0.015300083748247862], Loss = 2.7690851877226192\n",
      "Trial 23: Inputs = [0.05694887279401663, 0.015610658090811455, 0.05949762497788569], Loss = 3.0303346617690643\n",
      "Trial 24: Inputs = [0.003270702662134828, 0.007048642164735495, 0.0276969381996931], Loss = 2.4364684870656528\n",
      "Trial 25: Inputs = [0.02624365439391283, 0.006710720430530377, 0.021892066686757687], Loss = 2.5844820624501765\n",
      "Trial 26: Inputs = [0.015334848798471615, 0.044393785219418586, 0.000805398134321492], Loss = 2.8564263358928557\n",
      "Trial 27: Inputs = [0.01352519741164266, 0.02661066461962862, 0.1478369408005741], Loss = 3.071584609015808\n",
      "Trial 28: Inputs = [0.009886094158560529, 0.017817877192077388, 0.01722301595350366], Loss = 2.5663148223156327\n",
      "Trial 29: Inputs = [0.009222279709202379, 0.009665252220827862, 0.019716292171043936], Loss = 2.4833244417668876\n",
      "Trial 30: Inputs = [0.0492755506688286, 0.012311747700752051, 0.07603730842537139], Loss = 2.979887719719435\n",
      "Trial 31: Inputs = [0.027408751249640678, 0.024010415964694817, 0.056240156251517494], Loss = 2.878970966515128\n",
      "Trial 32: Inputs = [0.08407739246451412, 0.008241512138073184, 0.049250257137766026], Loss = 3.1391472578419854\n",
      "Trial 33: Inputs = [0.12266550630327146, 0.03227556743949545, 0.04026882345326492], Loss = 3.760162937487553\n",
      "Trial 34: Inputs = [0.006556364351332774, 0.0029854675557663603, 0.16112829314477298], Loss = 2.8197737523727655\n",
      "Trial 35: Inputs = [0.02741666182740938, 0.019616429998137223, 0.022854548338617157], Loss = 2.7352318599888434\n",
      "Trial 36: Inputs = [0.003916596229544538, 0.005010468343726475, 0.07083626107245161], Loss = 2.5460642200250234\n",
      "Trial 37: Inputs = [0.032868305266551184, 0.00390286709982957, 0.20320564953325296], Loss = 3.1552073585426124\n",
      "Trial 38: Inputs = [0.006444951112461028, 0.012203763691803244, 0.004878346376232227], Loss = 2.4473497229217895\n",
      "Trial 39: Inputs = [0.030580720645448305, 0.05926832860601948, 0.08505325532974575], Loss = 3.3991615928685537\n",
      "Trial 40: Inputs = [0.08356056885169337, 0.02431957328150027, 0.036739190425058854], Loss = 3.292369921562627\n",
      "Trial 41: Inputs = [0.014969848240440413, 0.0016095869492696445, 0.23293213636691631], Loss = 3.09707541351066\n",
      "Trial 42: Inputs = [0.06708412939662652, 0.010017296726720791, 0.013863383597534971], Loss = 2.9178490963449324\n",
      "Trial 43: Inputs = [0.0028239293617343293, 0.008023728283254816, 0.17765187977242092], Loss = 2.894389999308438\n",
      "Trial 44: Inputs = [0.026734644908693133, 0.01456270737386773, 0.084612928606328], Loss = 2.85385985176506\n",
      "Trial 45: Inputs = [0.08569590576081233, 0.015437688610916817, 0.11489268381075933], Loss = 3.4324262527978275\n",
      "Trial 46: Inputs = [0.005026358589043853, 0.10635494236975834, 0.15329702296919878], Loss = 3.970852449974219\n",
      "Trial 47: Inputs = [0.00855801146261807, 0.04049911115800571, 0.06585165334025406], Loss = 2.942050423060666\n",
      "Trial 48: Inputs = [0.005321910794782168, 0.0021731474542951035, 0.2390396539974933], Loss = 3.0536800439470118\n",
      "Trial 49: Inputs = [0.023445100672899195, 0.014334452169174904, 0.08157149035931617], Loss = 2.817326708756453\n",
      "Trial 50: Inputs = [0.0768128603699696, 0.001662708690900744, 0.013770537260849652], Loss = 2.9006901148385786\n",
      "Trial 51: Inputs = [0.0977881915885495, 0.017307833978793884, 0.13453991258826734], Loss = 3.6194698426391354\n",
      "Trial 52: Inputs = [0.014757889709950948, 0.028050128478753707, 0.07996572883612377], Loss = 2.8934887269741676\n",
      "Trial 53: Inputs = [0.04081434781538225, 0.02515655794846187, 0.07897882298693538], Loss = 3.0648933352225582\n",
      "Trial 54: Inputs = [0.015006618716475786, 0.0016832764979216024, 0.026011022836279138], Loss = 2.461634389158184\n",
      "Trial 55: Inputs = [0.04197838708694656, 0.016570284337362327, 0.007188353310196603], Loss = 2.7715557364278647\n",
      "Trial 56: Inputs = [0.03275950729078056, 0.08891894691519181, 0.06719523898834823], Loss = 3.747264608785614\n",
      "Trial 57: Inputs = [0.01167287664636051, 0.03652088351385861, 0.1663493048625157], Loss = 3.22138315147214\n",
      "Trial 58: Inputs = [0.038126279745174727, 0.04718551395888047, 0.20203209088246324], Loss = 3.669610769196626\n",
      "Trial 59: Inputs = [0.013926061774856557, 0.02057686522125426, 0.12084087118496162], Loss = 2.9284116872911308\n",
      "Trial 60: Inputs = [0.09431527966516581, 0.012535023203407856, 0.24196664337581603], Loss = 3.8723271595141764\n",
      "Trial 61: Inputs = [0.013956742040321787, 0.0199010270298994, 0.13223924650507587], Loss = 2.9560934618106884\n",
      "Trial 62: Inputs = [0.02710545254941887, 0.03796657076004433, 0.002373700829806669], Loss = 2.881930448119553\n",
      "Trial 63: Inputs = [0.019524468009198874, 0.04346070249465761, 0.10708687634224057], Loss = 3.18329353265868\n",
      "Trial 64: Inputs = [0.03316748086465812, 0.031275563794324314, 0.015439243139203003], Loss = 2.890979474188028\n",
      "Trial 65: Inputs = [0.060717970570498915, 0.6946828221362963, 0.5302923648727382], Loss = 19.56233916850279\n",
      "Trial 66: Inputs = [0.0006870026037391906, 0.00016586524345382932, 0.13733646876189876], Loss = 2.6771063268413275\n",
      "Trial 67: Inputs = [0.0360924628754331, 0.024684114490408707, 0.039263575707183765], Loss = 2.906796272076737\n",
      "Trial 68: Inputs = [0.13819305083328481, 0.059413726671020066, 0.03395131611394538], Loss = 4.274633664531024\n",
      "Trial 69: Inputs = [0.034423984760348865, 0.006041474084185421, 0.2733374639564566], Loss = 3.4193406177185652\n",
      "Trial 70: Inputs = [0.03486417413228817, 0.04556228528552046, 0.06785552619722725], Loss = 3.2206413002476015\n",
      "Trial 71: Inputs = [0.013769671666891992, 0.08099645281655282, 0.20911593113453025], Loss = 3.890559995244181\n",
      "Trial 72: Inputs = [0.12006140665498707, 0.0021948925055117405, 0.008712590455400954], Loss = 3.258788698948737\n",
      "Trial 73: Inputs = [0.3842622130218191, 0.8852199100332553, 0.5927077455506213], Loss = 35.60586781280391\n",
      "Trial 74: Inputs = [0.03977919744486184, 0.005809721196596439, 0.1551769199867583], Loss = 3.0753436261106666\n",
      "Trial 75: Inputs = [0.09381848822289904, 0.012916893109360774, 0.04995300168661568], Loss = 3.279931532607095\n",
      "Trial 76: Inputs = [0.07374856313234243, 0.0042038656263736094, 0.32452925666163357], Loss = 3.883844539270598\n",
      "Trial 77: Inputs = [0.07643608911238102, 0.0011696825169766993, 0.14745908877248384], Loss = 3.290231357215819\n",
      "Trial 78: Inputs = [0.02394124912337074, 0.021390298015094292, 0.05128677269952664], Loss = 2.808790875975963\n",
      "Trial 79: Inputs = [0.014931449366429237, 0.027019172672398728, 0.08545624659965334], Loss = 2.899697465088303\n",
      "Trial 80: Inputs = [0.008626101196472509, 0.017893779907467308, 0.07021389701423479], Loss = 2.709908587793934\n",
      "Trial 81: Inputs = [0.029535630638761072, 0.02050292686102639, 0.2354620186626204], Loss = 3.407320066898457\n",
      "Trial 82: Inputs = [0.019108371577037025, 0.0012378222754209356, 0.0222112100207489], Loss = 2.475889466537029\n",
      "Trial 83: Inputs = [0.3282240821270189, 0.11288377338844444, 0.6140014265620749], Loss = 9.420294754923367\n",
      "Trial 84: Inputs = [0.08392250176703071, 0.039342199415958755, 0.08218749954362346], Loss = 3.6140947258535054\n",
      "Trial 85: Inputs = [0.16310531260539943, 0.038663335062459656, 0.143965188981082], Loss = 4.550496717928917\n",
      "Trial 86: Inputs = [0.01602281351262788, 0.0076329731727556695, 0.2585041173907457], Loss = 3.248313233981892\n",
      "Trial 87: Inputs = [0.005640560978644003, 0.033274334044869125, 0.11921861435040557], Loss = 2.9960724413673523\n",
      "Trial 88: Inputs = [0.005375356152872843, 0.018730545094548825, 0.1451678000215075], Loss = 2.919242892131723\n",
      "Trial 89: Inputs = [0.012814942105098228, 0.046093217254759046, 0.06241531665182917], Loss = 3.0297612646051917\n",
      "Trial 90: Inputs = [0.8645733179440824, 0.4427562582912875, 0.32418309635576886], Loss = 30.178684968065877\n",
      "Trial 91: Inputs = [0.033923041459579945, 0.013779846359445642, 0.10304387814400677], Loss = 2.95574931378645\n",
      "Trial 92: Inputs = [0.2765559692511487, 0.21622482898079362, 0.19780383800630963], Loss = 9.409475087626607\n",
      "Trial 93: Inputs = [0.05680757815025569, 0.026000181177428392, 0.026628182657556287], Loss = 3.0556826380755835\n",
      "Trial 94: Inputs = [0.026944143183216314, 0.4227721100926157, 0.3855865756904617], Loss = 10.776052675843783\n",
      "Trial 95: Inputs = [0.5853487899722594, 0.12996276713111013, 0.8680754026681484], Loss = 15.032476359386289\n",
      "Trial 96: Inputs = [0.013605031384488264, 0.03215405470583177, 0.035993504740473414], Loss = 2.8032574102131127\n",
      "Trial 97: Inputs = [0.6342417611893675, 0.12994526527580735, 0.8890156467215342], Loss = 16.043196071763962\n",
      "Trial 98: Inputs = [0.6657085491390735, 0.21181259507403286, 0.6855987394840904], Loss = 18.10734987677754\n",
      "Trial 99: Inputs = [1e-07, 1e-07, 0.001670154815399773], Loss = 2.2692902524734935\n",
      "Trial 100: Inputs = [0.9050339030786307, 0.8731462280539649, 0.15200171699304788], Loss = 51.851884541301914\n",
      "Debug: Optimized lighter ingredients from Bayesian Optimization:\n",
      "[1e-07, 1e-07, 1e-07]\n",
      "Debug: Minimum error achieved:\n",
      "2.2645777391121564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1e-07, 1e-07, 1e-07]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesiann(trial) #error divided by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "03a4b03a-a3ae-4ee6-b9bb-db6e43490939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized heavy ingredients passed to bayesiann:\n",
      "[6.687910079956055, 6.379572868347168, 6.321332931518555, 5.336599349975586, 4.272467613220215, 1.6648460626602173]\n",
      "Trial History (Guessed Inputs and Corresponding Losses):\n",
      "Trial 1: Inputs = [0.5574396817667324, 0.5279668591641179, 0.8561068083898229], Loss = 0.497070085111368\n",
      "Trial 2: Inputs = [0.7539295569749173, 0.03886934215416717, 0.013633090209335936], Loss = 0.13179294040147363\n",
      "Trial 3: Inputs = [0.4633875429059946, 0.5998915348310422, 0.08766771214737554], Loss = 0.13723120893896004\n",
      "Trial 4: Inputs = [0.5338848704456247, 0.22192046354122805, 0.7596315432253532], Loss = 0.4149854784991331\n",
      "Trial 5: Inputs = [0.6321626748377455, 0.4943105625354395, 0.09026948893971057], Loss = 0.13759215229460967\n",
      "Trial 6: Inputs = [0.8445672333479876, 0.23231749941448326, 0.01668420804724873], Loss = 0.13389118439484532\n",
      "Trial 7: Inputs = [0.7059847559792597, 0.09417683337930893, 0.47352110779145984], Loss = 0.2377476959141136\n",
      "Trial 8: Inputs = [0.8488952284938576, 0.883370282414654, 0.604652899095959], Loss = 0.32213392751573355\n",
      "Trial 9: Inputs = [0.01724983185009452, 0.607989941634221, 0.03580685495567434], Loss = 0.13212208492860575\n",
      "Trial 10: Inputs = [0.7292730386998901, 0.03126578242225793, 0.9314106035325191], Loss = 0.5621244312991995\n",
      "Trial 11: Inputs = [0.036965918449352486, 0.03737899890776399, 0.07054830694541321], Loss = 0.1328980800561637\n",
      "Trial 12: Inputs = [1e-07, 1e-07, 0.2243444208620735], Loss = 0.15324840501061582\n",
      "Trial 13: Inputs = [1e-07, 1e-07, 1e-07], Loss = 0.13238281019324588\n",
      "Trial 14: Inputs = [1e-07, 1e-07, 0.03400255252051402], Loss = 0.13216850977769648\n",
      "Trial 15: Inputs = [1e-07, 1.0, 1e-07], Loss = 0.136335120305833\n",
      "Trial 16: Inputs = [0.9948013811219625, 0.9392637658147778, 0.3017968235725816], Loss = 0.1904305869444858\n",
      "Trial 17: Inputs = [0.2643642935488376, 1e-07, 0.02799976721119308], Loss = 0.1312315669606915\n",
      "Trial 18: Inputs = [1e-07, 1e-07, 0.03937789549443693], Loss = 0.13224506855555568\n",
      "Trial 19: Inputs = [0.9810603255890339, 0.011001751764003259, 0.11581776463981487], Loss = 0.1371546390678708\n",
      "Trial 20: Inputs = [1e-07, 1e-07, 0.031400233515103675], Loss = 0.1321422776302891\n",
      "Trial 21: Inputs = [0.997240999628499, 0.9654008095112888, 0.004406088571787413], Loss = 0.15086931312087\n",
      "Trial 22: Inputs = [0.021660960799706988, 0.9552941385360282, 0.15041994170139336], Loss = 0.14410226359716316\n",
      "Trial 23: Inputs = [0.016627261708472108, 0.31610097285014754, 0.019073824175851017], Loss = 0.13105238421032453\n",
      "Trial 24: Inputs = [0.36453207044831737, 0.1831338356534455, 0.0037648966877711076], Loss = 0.1314049770509627\n",
      "Trial 25: Inputs = [0.4317936361130407, 0.023636410969316363, 0.02728357155961325], Loss = 0.1310537855036981\n",
      "Trial 26: Inputs = [0.38050504348478364, 0.19186638756300417, 0.043082997028534006], Loss = 0.13147877451017878\n",
      "Trial 27: Inputs = [0.3881711295928879, 0.038321345104311635, 0.041512276104587596], Loss = 0.13122049354415186\n",
      "Trial 28: Inputs = [0.6087684716381003, 0.10360934927162403, 0.026468151791203046], Loss = 0.131560268678324\n",
      "Trial 29: Inputs = [0.166254737821083, 0.14500183178008194, 0.02371652645141981], Loss = 0.1310724409277471\n",
      "Trial 30: Inputs = [0.08919779450787434, 0.2673482118379236, 0.022483466338159997], Loss = 0.1310450787989567\n",
      "Trial 31: Inputs = [0.04667013046670421, 0.3566887786118591, 0.02711286096293209], Loss = 0.13111035408975974\n",
      "Trial 32: Inputs = [0.012047973817485836, 0.9780115707707772, 0.40792499246093794], Loss = 0.21315147538283805\n",
      "Trial 33: Inputs = [0.17894870643462715, 0.16408895542553043, 0.00902274265008481], Loss = 0.13115149338516605\n",
      "Trial 34: Inputs = [0.44025108224233117, 0.018774001298392087, 0.012116818881257492], Loss = 0.13110699734820735\n",
      "Trial 35: Inputs = [0.13931359456133127, 0.14994226445932712, 0.05742710768564689], Loss = 0.13170715887614268\n",
      "Trial 36: Inputs = [0.02521930799312634, 0.1630516001277299, 0.04366198982246644], Loss = 0.13145755229184203\n",
      "Trial 37: Inputs = [0.3672632202935614, 0.9178115373540766, 0.015041006260861377], Loss = 0.13902812553981464\n",
      "Trial 38: Inputs = [0.07917006414489695, 0.36163752222353834, 0.012412746479259426], Loss = 0.131213435570877\n",
      "Trial 39: Inputs = [0.4557276694916752, 0.13357329511406674, 0.03874577136586475], Loss = 0.1313822233506907\n",
      "Trial 40: Inputs = [0.19646965280071, 0.25922571971141206, 0.027692868076062756], Loss = 0.1311271694392108\n",
      "Trial 41: Inputs = [0.3138082122081725, 0.21691221509819564, 0.0007556371895020016], Loss = 0.13146469208529662\n",
      "Trial 42: Inputs = [0.3831880149698137, 0.021998248548970124, 0.0417308285410727], Loss = 0.13123001764415332\n",
      "Trial 43: Inputs = [0.22443007593729936, 0.11042186192592417, 0.021106618048689695], Loss = 0.13106721549922545\n",
      "Trial 44: Inputs = [0.24590930930565338, 0.19731275876299914, 0.013194992745375889], Loss = 0.1311264367187853\n",
      "Trial 45: Inputs = [0.2438513534368251, 0.5083694001441907, 0.040261197317194505], Loss = 0.13262621213425985\n",
      "Trial 46: Inputs = [0.6838493861236745, 0.06348316302110836, 0.019615609370754305], Loss = 0.13162266652863203\n",
      "Trial 47: Inputs = [0.21272836787854313, 0.10059945968791328, 0.0281564936417297], Loss = 0.13110030163153075\n",
      "Trial 48: Inputs = [0.48265840088264195, 0.15359078787878233, 0.028350769700267054], Loss = 0.13140196322655293\n",
      "Trial 49: Inputs = [0.40274185909147986, 0.1697088154634846, 0.0404252648096774], Loss = 0.13140726543352615\n",
      "Trial 50: Inputs = [0.23330267328896456, 0.28510713796296755, 0.00983026228008494], Loss = 0.1313278080282463\n",
      "Trial 51: Inputs = [0.18401083932212056, 0.20598950702536004, 0.035755958034755016], Loss = 0.13113142968929992\n",
      "Trial 52: Inputs = [0.37013528245041705, 0.01399605558236385, 0.032801745568568394], Loss = 0.13110890190065375\n",
      "Trial 53: Inputs = [0.03952549995386387, 0.22969601077343235, 0.01498350588327201], Loss = 0.13111188504447\n",
      "Trial 54: Inputs = [0.261048106260067, 0.10467545765191125, 0.011625227652937229], Loss = 0.1311176879274161\n",
      "Trial 55: Inputs = [0.43436266108531063, 0.2290699337892421, 0.054536105846069674], Loss = 0.13208186385366563\n",
      "Trial 56: Inputs = [0.12423120811752321, 0.13338509451553854, 0.035250165547679124], Loss = 0.13121488001417772\n",
      "Trial 57: Inputs = [0.3841832113238936, 0.012871111521679503, 0.054845261420132796], Loss = 0.13158030573208152\n",
      "Trial 58: Inputs = [0.22247490592966676, 0.20647983122913655, 0.022521018334277755], Loss = 0.13106773745583686\n",
      "Trial 59: Inputs = [0.0015781521914291258, 0.40229386389442917, 0.04264778384078584], Loss = 0.1313261493898227\n",
      "Trial 60: Inputs = [0.13611797449612958, 0.19621318428056864, 0.021601191919350577], Loss = 0.13104911532148908\n",
      "Trial 61: Inputs = [0.26003203675469266, 0.009792362161322173, 0.034776250671427714], Loss = 0.1312725906604481\n",
      "Trial 62: Inputs = [0.2618213452220026, 0.2837356285311848, 0.02845116850031345], Loss = 0.13130997659316943\n",
      "Trial 63: Inputs = [0.2867393055451714, 0.27177592680888757, 0.03205520288160327], Loss = 0.1313560230391145\n",
      "Trial 64: Inputs = [0.013279257044871758, 0.33494155510799223, 0.009963501662099604], Loss = 0.13114074098674477\n",
      "Trial 65: Inputs = [0.5075348804394896, 0.05806952210734605, 0.053045147749266656], Loss = 0.13162254050142722\n",
      "Trial 66: Inputs = [0.13000565644137663, 0.289051883133146, 0.014703246434603821], Loss = 0.1311248909028897\n",
      "Trial 67: Inputs = [0.36549697244380813, 0.006436469009220025, 0.03555784472742276], Loss = 0.1311513774472762\n",
      "Trial 68: Inputs = [0.06808243277711178, 0.31048749639558165, 0.0596684044156079], Loss = 0.13176251834118335\n",
      "Trial 69: Inputs = [0.446456902415274, 1e-07, 0.022753133322758256], Loss = 0.13104244987894817\n",
      "Trial 70: Inputs = [0.09665619995837138, 0.12451112982792746, 0.011919883005923768], Loss = 0.13126734542615812\n",
      "Trial 71: Inputs = [0.338157038180355, 0.3688376415517637, 0.043041060551351144], Loss = 0.13216721014031882\n",
      "Trial 72: Inputs = [0.41595040630519003, 0.0569528285648453, 0.038165830161448866], Loss = 0.13117543153775663\n",
      "Trial 73: Inputs = [0.05861330312472939, 0.30314156221759364, 0.03479619629262065], Loss = 0.13112375434834825\n",
      "Trial 74: Inputs = [0.5281094829908323, 0.07083616708933496, 0.035050481713947666], Loss = 0.1312954475305112\n",
      "Trial 75: Inputs = [0.677400498534754, 0.023621954238296453, 0.04972722891260354], Loss = 0.13178903110401313\n",
      "Trial 76: Inputs = [0.3010885681740461, 0.27523366353643236, 0.017221735501778714], Loss = 0.1313796121531175\n",
      "Trial 77: Inputs = [0.4147544020884713, 0.21909538846571647, 0.01945595723958565], Loss = 0.1314644648760321\n",
      "Trial 78: Inputs = [0.10380554120379083, 0.35009267834188446, 0.024198394391045923], Loss = 0.1311684183924259\n",
      "Trial 79: Inputs = [0.049297122934970725, 0.41000775497293346, 0.03977947339919849], Loss = 0.13136829242695935\n",
      "Trial 80: Inputs = [0.8143170132849811, 0.07414465154295713, 0.005574485782452414], Loss = 0.13239901593571043\n",
      "Trial 81: Inputs = [0.9020498245263685, 0.20718385861401753, 0.054927068415656956], Loss = 0.13457369015332157\n",
      "Trial 82: Inputs = [0.4777002779680991, 0.09346405395174247, 0.011747597685845181], Loss = 0.13125267571111512\n",
      "Trial 83: Inputs = [0.06583792259774901, 0.19505522522232607, 0.07262497298507985], Loss = 0.13238327072351488\n",
      "Trial 84: Inputs = [0.13305742007398963, 0.01974980752277929, 0.0035965448249182957], Loss = 0.13167389282934353\n",
      "Trial 85: Inputs = [0.42929046134930265, 0.011391816692294913, 0.02286443167391452], Loss = 0.13104242597761528\n",
      "Trial 86: Inputs = [0.27537780484397384, 0.04308563904662934, 0.011004466063981946], Loss = 0.1311822844554778\n",
      "Trial 87: Inputs = [0.07421471593705604, 0.42113151568578316, 0.03302614697198714], Loss = 0.13136264705630268\n",
      "Trial 88: Inputs = [0.07115450530787999, 0.3699450901821052, 0.03791905241640139], Loss = 0.13127584635350725\n",
      "Trial 89: Inputs = [0.3330348303782185, 0.09058779231002889, 0.012797532807674886], Loss = 0.13109841000500178\n",
      "Trial 90: Inputs = [0.5255846163940869, 0.7750933273494642, 0.159071817877786], Loss = 0.14809142843221076\n",
      "Trial 91: Inputs = [0.2404076032810918, 0.04679353336153908, 0.009594351591745381], Loss = 0.13124061177427582\n",
      "Trial 92: Inputs = [0.19088273078094514, 0.1441953624136246, 0.00919965445438758], Loss = 0.13115637183095258\n",
      "Trial 93: Inputs = [0.3414346419905092, 0.03937843452122752, 0.042021774026546686], Loss = 0.13124312934370544\n",
      "Trial 94: Inputs = [0.12344933158938054, 0.10820070363713445, 0.00990831661632335], Loss = 0.1312859764620179\n",
      "Trial 95: Inputs = [0.6323216472427992, 0.1906212098174065, 0.007129745810318978], Loss = 0.13228629223754407\n",
      "Trial 96: Inputs = [0.6893743893047453, 0.49909782518035795, 0.07935089624785355], Loss = 0.1375160884222438\n",
      "Trial 97: Inputs = [0.2096749078440322, 0.11076037552397175, 0.04265425740801779], Loss = 0.13127703047875314\n",
      "Trial 98: Inputs = [0.28862526953727263, 0.04755351454860628, 0.05417742952288646], Loss = 0.13159161322199484\n",
      "Trial 99: Inputs = [0.12833875559383032, 0.30129863428171, 0.020802061935313917], Loss = 0.13110810174845167\n",
      "Trial 100: Inputs = [0.12647761162251075, 0.2264276467033338, 0.02297116672526367], Loss = 0.1310424658000803\n",
      "Debug: Optimized lighter ingredients from Bayesian Optimization:\n",
      "[0.42929046134930265, 0.011391816692294913, 0.02286443167391452]\n",
      "Debug: Minimum error achieved:\n",
      "0.13104242597761528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42929046134930265, 0.011391816692294913, 0.02286443167391452]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesiann(trial) #error divided by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4813dcdb-fcd2-4182-a465-ab9e31cc4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized heavy ingredients passed to bayesiann:\n",
      "[6.569365978240967, 5.498148441314697, 5.273582935333252, 5.364184379577637, 4.248894691467285, 3.4599080085754395]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1.0] before, using random point [0.542077266451464, 0.6176488728090731, 0.8124382379430596]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial History (Guessed Inputs and Corresponding Losses):\n",
      "Trial 1: Inputs = [0.5574396817667324, 0.5279668591641179, 0.8561068083898229], Loss = 3.0036423428909083\n",
      "Trial 2: Inputs = [0.7539295569749173, 0.03886934215416717, 0.013633090209335936], Loss = 5.434281513603801\n",
      "Trial 3: Inputs = [0.4633875429059946, 0.5998915348310422, 0.08766771214737554], Loss = 5.19396377489779\n",
      "Trial 4: Inputs = [0.5338848704456247, 0.22192046354122805, 0.7596315432253532], Loss = 3.2417800149891707\n",
      "Trial 5: Inputs = [0.6321626748377455, 0.4943105625354395, 0.09026948893971057], Loss = 5.185687963400658\n",
      "Trial 6: Inputs = [0.8445672333479876, 0.23231749941448326, 0.01668420804724873], Loss = 5.426208716817941\n",
      "Trial 7: Inputs = [0.7059847559792597, 0.09417683337930893, 0.47352110779145984], Loss = 4.0140365712256285\n",
      "Trial 8: Inputs = [0.8488952284938576, 0.883370282414654, 0.604652899095959], Loss = 3.66308818358855\n",
      "Trial 9: Inputs = [0.01724983185009452, 0.607989941634221, 0.03580685495567434], Loss = 5.361015726935123\n",
      "Trial 10: Inputs = [0.7292730386998901, 0.03126578242225793, 0.9314106035325191], Loss = 2.818857946652762\n",
      "Trial 11: Inputs = [1e-07, 1e-07, 1.0], Loss = 2.6592902364123563\n",
      "Trial 12: Inputs = [1.0, 1e-07, 1.0], Loss = 2.659743247788082\n",
      "Trial 13: Inputs = [1e-07, 1.0, 1.0], Loss = 2.663066001075603\n",
      "Trial 14: Inputs = [0.8956907068106529, 0.9827928924234455, 1.0], Loss = 2.676041561284268\n",
      "Trial 15: Inputs = [0.542077266451464, 0.6176488728090731, 0.8124382379430596], Loss = 3.112671990520418\n",
      "Trial 16: Inputs = [0.02117987037539205, 0.1294000805746393, 1.0], Loss = 2.658513855006536\n",
      "Trial 17: Inputs = [0.5085591083252043, 0.007249526494580544, 0.999143338338504], Loss = 2.660160432322445\n",
      "Trial 18: Inputs = [0.022358866865202685, 0.008675846496619895, 0.9969496395839855], Loss = 2.666145363048471\n",
      "Trial 19: Inputs = [0.9873718850616343, 0.05456918823942321, 0.9979182393648078], Loss = 2.6649285908673797\n",
      "Trial 20: Inputs = [0.032275270181085426, 0.025624542157705, 0.9974171771174596], Loss = 2.6649218768585667\n",
      "Trial 21: Inputs = [0.8719683838690289, 0.1465746158272144, 0.9997094297243455], Loss = 2.6609049269070306\n",
      "Trial 22: Inputs = [0.13071748542066325, 0.03313673708380064, 0.999752070328846], Loss = 2.659159840608179\n",
      "Trial 23: Inputs = [0.037257954424113324, 0.0995229600373749, 0.999369799723395], Loss = 2.6600376212621066\n",
      "Trial 24: Inputs = [0.02299010786356007, 0.8480469582165944, 0.9993902491225395], Loss = 2.6627010541681\n",
      "Trial 25: Inputs = [0.06485361594223446, 0.9424373227599673, 0.9995014260468438], Loss = 2.664044371337522\n",
      "Trial 26: Inputs = [0.0901085889002894, 0.022325874799481036, 0.9997454788845177], Loss = 2.659359114425049\n",
      "Trial 27: Inputs = [0.8222793597176878, 0.14716401508999932, 0.9999634085612543], Loss = 2.660008917117026\n",
      "Trial 28: Inputs = [0.006579207792880062, 0.8711832982586191, 0.9998412826086669], Loss = 2.6617987449437734\n",
      "Trial 29: Inputs = [0.957690491071937, 0.28222433993535917, 0.9997900791243111], Loss = 2.662976968731861\n",
      "Trial 30: Inputs = [0.9871956628012439, 0.08661086565999071, 0.9991704073523083], Loss = 2.6623516440563373\n",
      "Trial 31: Inputs = [0.050002864397266526, 0.1825610604654387, 0.9996225499536592], Loss = 2.6591577248830274\n",
      "Trial 32: Inputs = [0.8090912717188727, 0.0744569228125288, 0.9998550337284194], Loss = 2.659619328942022\n",
      "Trial 33: Inputs = [0.009480443492005424, 0.634689056730553, 0.9998844025227605], Loss = 2.6595171791099443\n",
      "Trial 34: Inputs = [0.08649095543811436, 0.33945355376076924, 0.9991753522665663], Loss = 2.6601304091314852\n",
      "Trial 35: Inputs = [0.4800117876085618, 0.3991315947540928, 0.9998735519775981], Loss = 2.6603032379288587\n",
      "Trial 36: Inputs = [0.6392779305773818, 0.8986316166149398, 0.9997575795363068], Loss = 2.670012365086893\n",
      "Trial 37: Inputs = [0.03652524578854487, 0.11517412815213825, 1.0], Loss = 2.6585269187843177\n",
      "Trial 38: Inputs = [0.042750521077244155, 0.7215876195109397, 0.9993762996253202], Loss = 2.661566978101422\n",
      "Trial 39: Inputs = [0.005362417473520266, 0.4241973723475275, 0.9978320510217044], Loss = 2.6632742059604233\n",
      "Trial 40: Inputs = [0.18132046532303248, 0.011218207875545809, 1.0], Loss = 2.658533123283776\n",
      "Trial 41: Inputs = [0.03428940107840024, 0.15248647909168314, 1.0], Loss = 2.6584010336093375\n",
      "Trial 42: Inputs = [0.46113187899535485, 1e-07, 1.0], Loss = 2.6581704809999214\n",
      "Trial 43: Inputs = [0.28024361039329393, 0.08115456721959155, 0.9990636101702494], Loss = 2.6603447825060895\n",
      "Trial 44: Inputs = [0.18199498604808642, 0.667507966936946, 0.9997216358724067], Loss = 2.661200365151703\n",
      "Trial 45: Inputs = [0.5496754081783217, 0.5666861264004502, 0.9993911794234989], Loss = 2.663840189330646\n",
      "Trial 46: Inputs = [0.17212592200377363, 0.22306669363399184, 1.0], Loss = 2.6581752932099554\n",
      "Trial 47: Inputs = [0.1088334701232595, 0.6098932435645781, 0.9998041431456769], Loss = 2.660032859428212\n",
      "Trial 48: Inputs = [0.7468277621737485, 0.017110732455916808, 0.9980764037410315], Loss = 2.6631201959114525\n",
      "Trial 49: Inputs = [0.05542070079025399, 0.46480702000938173, 0.998437980563189], Loss = 2.6621115256119956\n",
      "Trial 50: Inputs = [0.48644794170378336, 0.022032631441469323, 0.9970444611904717], Loss = 2.66498953462373\n",
      "Trial 51: Inputs = [0.2289703563877085, 3.039365928630159e-07, 1.0], Loss = 2.658450000316204\n",
      "Trial 52: Inputs = [0.25964379970088736, 0.425220615432695, 0.9988008282403478], Loss = 2.661798811194047\n",
      "Trial 53: Inputs = [1e-07, 0.25555207430424076, 1.0], Loss = 2.6582199355096594\n",
      "Trial 54: Inputs = [0.5667641802810461, 1e-07, 1.0], Loss = 2.658234089501697\n",
      "Trial 55: Inputs = [0.6366244076182133, 0.09112931408127994, 0.9994068244100546], Loss = 2.660041299023384\n",
      "Trial 56: Inputs = [0.6503932962084191, 0.2870706665389594, 0.998355264119028], Loss = 2.6638707133459945\n",
      "Trial 57: Inputs = [0.4877626853334088, 0.08540861955432205, 1.0], Loss = 2.6582922457686022\n",
      "Trial 58: Inputs = [0.08099364093769432, 0.18587800939840476, 1.0], Loss = 2.658239621389289\n",
      "Trial 59: Inputs = [0.8478628414665679, 0.05518970005050352, 0.9999293587057608], Loss = 2.6595054020776883\n",
      "Trial 60: Inputs = [0.4520234873180657, 0.2659458797109457, 0.9989703837633733], Loss = 2.6612725247230733\n",
      "Trial 61: Inputs = [0.46742481594303453, 0.08746308021046027, 1.0], Loss = 2.6582657351600827\n",
      "Trial 62: Inputs = [0.7053123836829066, 0.269186932980044, 1.0], Loss = 2.660282134352599\n",
      "Trial 63: Inputs = [1e-07, 0.2721241412604689, 1.0], Loss = 2.6581987719342854\n",
      "Trial 64: Inputs = [0.09727176316821919, 0.07309211883423815, 1.0], Loss = 2.658523539196154\n",
      "Trial 65: Inputs = [0.1991996325571717, 0.24005051427362, 1.0], Loss = 2.658205656151339\n",
      "Trial 66: Inputs = [1e-07, 0.2663966971635996, 1.0], Loss = 2.6582054217801905\n",
      "Trial 67: Inputs = [0.704281593771951, 0.056463317333032635, 0.39888537873888386], Loss = 4.2293385432164445\n",
      "Trial 68: Inputs = [0.33191578335004857, 0.20050202773688028, 0.9996682160595751], Loss = 2.6590666426223115\n",
      "Trial 69: Inputs = [0.1575578405105348, 0.19920181261575812, 1.0], Loss = 2.6581722646972223\n",
      "Trial 70: Inputs = [0.3939219605606139, 0.20545019871858994, 0.9997417300870953], Loss = 2.659039566152471\n",
      "Trial 71: Inputs = [0.5904737390868952, 0.4059999422571457, 0.99935139470888], Loss = 2.6623355111456277\n",
      "Trial 72: Inputs = [0.8147274298972995, 1e-07, 1.0], Loss = 2.658852216799944\n",
      "Trial 73: Inputs = [0.38080102214101075, 0.4422315337237344, 1.0], Loss = 2.6597802756743376\n",
      "Trial 74: Inputs = [0.4667962660412607, 0.05139620171100258, 0.9982202024533043], Loss = 2.6622999888813714\n",
      "Trial 75: Inputs = [1e-07, 0.27155359457137945, 1.0], Loss = 2.658199402891593\n",
      "Trial 76: Inputs = [0.3003926975982461, 0.34198785891457273, 0.9992603897219117], Loss = 2.660441245710264\n",
      "Trial 77: Inputs = [0.4627986607392239, 0.08518339155878073, 0.9996980192161213], Loss = 2.658949212598897\n",
      "Trial 78: Inputs = [1e-07, 0.27374272510284203, 1.0], Loss = 2.658197019877001\n",
      "Trial 79: Inputs = [0.7082559976535168, 0.22342531991183717, 0.9996430004128987], Loss = 2.660708189135985\n",
      "Trial 80: Inputs = [0.12267177647470719, 0.175135195951618, 1.0], Loss = 2.6582111611444206\n",
      "Trial 81: Inputs = [0.7726663822699166, 1e-07, 1.0], Loss = 2.658701059406772\n",
      "Trial 82: Inputs = [0.25177072578177395, 0.2669043133135628, 0.999905247095622], Loss = 2.658545910716969\n",
      "Trial 83: Inputs = [0.3172015902499243, 0.05114689280443528, 1.0], Loss = 2.658195220097842\n",
      "Trial 84: Inputs = [1e-07, 0.49794331085002463, 1.0], Loss = 2.6584959478686803\n",
      "Trial 85: Inputs = [0.016611017240463155, 0.30350179763796026, 1.0], Loss = 2.658171236717302\n",
      "Trial 86: Inputs = [0.5134914074649368, 0.09569548203406007, 0.99918557385849], Loss = 2.6602387965962926\n",
      "Trial 87: Inputs = [1e-07, 0.26927801553931086, 1.0], Loss = 2.6582019886986834\n",
      "Trial 88: Inputs = [0.08323424487351404, 0.18937987300494208, 1.0], Loss = 2.6582311501609035\n",
      "Trial 89: Inputs = [0.33558254024418166, 0.10346585175371088, 1.0], Loss = 2.6581736000827374\n",
      "Trial 90: Inputs = [0.04431568579770199, 0.48206277084264243, 1.0], Loss = 2.658556146151759\n",
      "Trial 91: Inputs = [0.04418963938191782, 0.4451391469159251, 0.9998837955270814], Loss = 2.658687626628685\n",
      "Trial 92: Inputs = [0.29719415689921713, 0.45459122378029676, 1.0], Loss = 2.659415667895362\n",
      "Trial 93: Inputs = [1e-07, 0.2838023953346885, 1.0], Loss = 2.6581873874265542\n",
      "Trial 94: Inputs = [1e-07, 0.28416401209091124, 1.0], Loss = 2.658187081481945\n",
      "Trial 95: Inputs = [0.28753240039079736, 0.6665059111871366, 0.9996103943498932], Loss = 2.662258503910892\n",
      "Trial 96: Inputs = [0.15291524110316151, 0.391235742440203, 1.0], Loss = 2.658501161426571\n",
      "Trial 97: Inputs = [0.10084863775749237, 0.07502516834037248, 1.0], Loss = 2.658506409090124\n",
      "Trial 98: Inputs = [0.3255492427683479, 0.3198503074602128, 1.0], Loss = 2.6587191630641764\n",
      "Trial 99: Inputs = [1e-07, 0.2879791596238052, 1.0], Loss = 2.6581840241587344\n",
      "Trial 100: Inputs = [0.3933869340633341, 0.11314490885354678, 1.0], Loss = 2.6582195080402675\n",
      "Debug: Optimized lighter ingredients from Bayesian Optimization:\n",
      "[0.46113187899535485, 1e-07, 1.0]\n",
      "Debug: Minimum error achieved:\n",
      "2.6581704809999214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46113187899535485, 1e-07, 1.0]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesiann(trial) #error divided by nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d1ebc342-c2bc-4187-bfe2-520b73053232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized heavy ingredients passed to bayesiann:\n",
      "[6.569365978240967, 5.498148441314697, 5.273582935333252, 5.364184379577637, 4.248894691467285, 3.4599080085754395]\n",
      "Trial History (Guessed Inputs and Corresponding Losses):\n",
      "Trial 1: Inputs = [0.5574396817667324, 0.5279668591641179, 0.8561068083898229], Loss = 2.999810082515677\n",
      "Trial 2: Inputs = [0.7539295569749173, 0.03886934215416717, 0.013633090209335936], Loss = 5.433621804004859\n",
      "Trial 3: Inputs = [0.4633875429059946, 0.5998915348310422, 0.08766771214737554], Loss = 5.190061740747148\n",
      "Trial 4: Inputs = [0.5338848704456247, 0.22192046354122805, 0.7596315432253532], Loss = 3.2409661482496923\n",
      "Trial 5: Inputs = [0.6321626748377455, 0.4943105625354395, 0.09026948893971057], Loss = 5.181606375590632\n",
      "Trial 6: Inputs = [0.8445672333479876, 0.23231749941448326, 0.01668420804724873], Loss = 5.423471245717233\n",
      "Trial 7: Inputs = [0.7059847559792597, 0.09417683337930893, 0.47352110779145984], Loss = 4.013258166164081\n",
      "Trial 8: Inputs = [0.8488952284938576, 0.883370282414654, 0.604652899095959], Loss = 3.6486938456701874\n",
      "Trial 9: Inputs = [0.01724983185009452, 0.607989941634221, 0.03580685495567434], Loss = 5.360074400444299\n",
      "Trial 10: Inputs = [0.7292730386998901, 0.03126578242225793, 0.9314106035325191], Loss = 2.8183245026725756\n",
      "Trial 11: Inputs = [0.8308854257591127, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 12: Inputs = [1e-07, 1.0, 1.0], Loss = 2.6581707083567108\n",
      "Trial 13: Inputs = [1.0, 1.0, 1.0], Loss = 2.6581707083567108\n",
      "Trial 14: Inputs = [1e-07, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 15: Inputs = [0.9874093318955983, 0.5339418246128024, 1.0], Loss = 2.6581705675276632\n",
      "Trial 16: Inputs = [0.1978953930399878, 0.940946021958031, 1.0], Loss = 2.6581706900824513\n",
      "Trial 17: Inputs = [1.0, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 18: Inputs = [0.8003713204862424, 0.8934969346866181, 0.9998955197220729], Loss = 2.658410900406004\n",
      "Trial 19: Inputs = [0.17669263964123424, 0.7705443242214096, 0.9999531396198], Loss = 2.658278379760167\n",
      "Trial 20: Inputs = [0.45566352169946694, 0.020049519523808738, 0.9994408724283173], Loss = 2.6594561206582106\n",
      "Trial 21: Inputs = [0.14895821989894872, 0.1741478601828011, 0.9994758460361792], Loss = 2.6593757330575145\n",
      "Trial 22: Inputs = [0.1307173797588027, 0.03313663897229212, 0.9997798986342544], Loss = 2.6586765033314648\n",
      "Trial 23: Inputs = [0.19344170655069218, 0.9158914207039452, 0.9998103258255087], Loss = 2.658606796669662\n",
      "Trial 24: Inputs = [0.8866258774256764, 0.18708646866958256, 0.9997303611769413], Loss = 2.6587904545432055\n",
      "Trial 25: Inputs = [0.06485361594223446, 0.9424373227599673, 0.9995014260468438], Loss = 2.6593171327158913\n",
      "Trial 26: Inputs = [0.0901085889002894, 0.022325874799481036, 0.9997454788845177], Loss = 2.6587556461583994\n",
      "Trial 27: Inputs = [1.0, 0.7587391058013195, 1.0], Loss = 2.6581706344847498\n",
      "Trial 28: Inputs = [0.006579207792880062, 0.8711832982586191, 0.9998412826086669], Loss = 2.6585356020383264\n",
      "Trial 29: Inputs = [0.957690491071937, 0.28222433993535917, 0.9997900791243111], Loss = 2.658653164081376\n",
      "Trial 30: Inputs = [0.9871956628012439, 0.08661086565999071, 0.9991704073523083], Loss = 2.6600781835935208\n",
      "Trial 31: Inputs = [0.050002864397266526, 0.1825610604654387, 0.9996225499536592], Loss = 2.65903836734054\n",
      "Trial 32: Inputs = [0.8090912717188727, 0.0744569228125288, 0.9998550337284194], Loss = 2.6585037511624914\n",
      "Trial 33: Inputs = [0.9657686192526124, 0.8063435545425438, 0.9996633041572622], Loss = 2.6589448332138317\n",
      "Trial 34: Inputs = [0.8459280843314603, 0.8486843384561792, 0.9999526321835646], Loss = 2.6582795702044204\n",
      "Trial 35: Inputs = [0.03706816929786223, 0.10688529338598993, 0.9993151559465487], Loss = 2.659745271434317\n",
      "Trial 36: Inputs = [0.7285436640354452, 0.9837736020998135, 0.9996481717773529], Loss = 2.6589796851792036\n",
      "Trial 37: Inputs = [0.21335459054896422, 0.9471379394711597, 0.9990316350289297], Loss = 2.660397628989053\n",
      "Trial 38: Inputs = [0.1636325740189655, 0.9826049200596552, 0.9997294113580043], Loss = 2.65879287381748\n",
      "Trial 39: Inputs = [0.2841264133111838, 0.07845380573965562, 0.9996578378052832], Loss = 2.6589571917947223\n",
      "Trial 40: Inputs = [0.8228745570255916, 0.9155418986126517, 0.9994832751707061], Loss = 2.659358866223754\n",
      "Trial 41: Inputs = [0.9999624076047107, 0.5400928775716974, 0.9999775688772737], Loss = 2.658222142841836\n",
      "Trial 42: Inputs = [0.8399517624633192, 0.07171633559446809, 0.9995075385313444], Loss = 2.6593028208269645\n",
      "Trial 43: Inputs = [0.009633411719712527, 0.9893897246547747, 0.9990941916652055], Loss = 2.66025375177043\n",
      "Trial 44: Inputs = [0.033336676670881665, 0.25175370574803485, 0.9993567080937695], Loss = 2.659649747403161\n",
      "Trial 45: Inputs = [0.8410774991527575, 0.02161086576585094, 0.9999372506971795], Loss = 2.658314695831551\n",
      "Trial 46: Inputs = [0.06101584041751573, 0.08552165084647712, 0.9993742597149489], Loss = 2.6596093347302556\n",
      "Trial 47: Inputs = [0.1910199010623972, 0.9625736091200505, 0.9991641820033511], Loss = 2.660092759311193\n",
      "Trial 48: Inputs = [0.9368679879891885, 0.973794860628369, 0.998986454114254], Loss = 2.6605015631136126\n",
      "Trial 49: Inputs = [0.05315487900470153, 0.5914058709898891, 0.999712928484073], Loss = 2.65883065725845\n",
      "Trial 50: Inputs = [0.0007080036109988223, 0.22532849042181066, 0.9994796206275953], Loss = 2.659367066952909\n",
      "Trial 51: Inputs = [0.9798764672965504, 0.7411187837385284, 1.0], Loss = 2.658170629171149\n",
      "Trial 52: Inputs = [0.25395776153657484, 0.9347647140824793, 0.999998875295871], Loss = 2.6581732740775044\n",
      "Trial 53: Inputs = [0.03318502971497795, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 54: Inputs = [0.8687943355855874, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 55: Inputs = [0.9016971214786981, 0.8317853560944589, 0.9999171053191577], Loss = 2.658361250211258\n",
      "Trial 56: Inputs = [0.7213757659832134, 0.8449367922541685, 0.9996749598766553], Loss = 2.6589180423069396\n",
      "Trial 57: Inputs = [0.9916764861441264, 0.25465212088411604, 0.9998180261809346], Loss = 2.658588895145304\n",
      "Trial 58: Inputs = [0.5337956646519673, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 59: Inputs = [0.16541643482876625, 0.08894411378711488, 0.9998933458840809], Loss = 2.658415663519565\n",
      "Trial 60: Inputs = [0.9322871341825515, 0.048519454560272054, 0.9997664752072022], Loss = 2.65870737366495\n",
      "Trial 61: Inputs = [0.0337870701707951, 0.8021538601699447, 0.9999447568114064], Loss = 2.6582976633860143\n",
      "Trial 62: Inputs = [0.9925724984580977, 0.914421226463264, 0.9996661554301344], Loss = 2.658938309638813\n",
      "Trial 63: Inputs = [0.050397675721525696, 0.8974891549861096, 0.9999764232737418], Loss = 2.658224884199541\n",
      "Trial 64: Inputs = [0.07561292384933643, 1.0, 1.0], Loss = 2.6581707083567108\n",
      "Trial 65: Inputs = [0.8940578287699676, 0.9957500405601644, 0.9991501216852429], Loss = 2.6601251091905778\n",
      "Trial 66: Inputs = [0.8645167194270018, 0.292278701529173, 1.0], Loss = 2.6581704975631846\n",
      "Trial 67: Inputs = [0.9537911168988427, 0.9621498086482926, 0.9995848985329674], Loss = 2.6591251805366984\n",
      "Trial 68: Inputs = [0.6507789976902838, 0.29565367741328913, 0.9999997747335979], Loss = 2.6581710164544665\n",
      "Trial 69: Inputs = [0.05293401645562086, 0.13620664667380056, 0.9995764101745032], Loss = 2.659144457394872\n",
      "Trial 70: Inputs = [0.12672781973569258, 0.03900527102879118, 0.998764905079476], Loss = 2.6610109309364818\n",
      "Trial 71: Inputs = [0.5224435586687641, 0.7201831637894273, 0.9999590770829805], Loss = 2.658264712998389\n",
      "Trial 72: Inputs = [0.929909303138696, 0.08700162310623907, 1.0], Loss = 2.6581704397738717\n",
      "Trial 73: Inputs = [1e-07, 0.8749598404679219, 1.0], Loss = 2.658170669810595\n",
      "Trial 74: Inputs = [0.8951115667698478, 0.02684072068260626, 0.9996800213341325], Loss = 2.6589061658738387\n",
      "Trial 75: Inputs = [0.7953616097712762, 0.972557653942101, 0.9993666581675326], Loss = 2.6596270775546857\n",
      "Trial 76: Inputs = [0.898734151632351, 0.4726546135173645, 0.9998900035931856], Loss = 2.6584234577067813\n",
      "Trial 77: Inputs = [1.0, 0.12974881088089485, 1.0], Loss = 2.658170451683735\n",
      "Trial 78: Inputs = [0.07665041882115178, 0.3652698336548742, 0.999328767738691], Loss = 2.6597140389793714\n",
      "Trial 79: Inputs = [0.9696454822302278, 0.02573715551891781, 0.9991664228280959], Loss = 2.6600873313527313\n",
      "Trial 80: Inputs = [0.9964728513291655, 0.9868531900115244, 0.9992482845268127], Loss = 2.6598993301218434\n",
      "Trial 81: Inputs = [0.3448490248713897, 0.5030183390282518, 0.9995122012656377], Loss = 2.6592922208926852\n",
      "Trial 82: Inputs = [0.942011407817271, 0.9492032906561126, 1.0], Loss = 2.6581706926301623\n",
      "Trial 83: Inputs = [0.026671340761048618, 0.770384457078306, 0.9982418805891676], Loss = 2.662214487987405\n",
      "Trial 84: Inputs = [0.31330930617082586, 0.29502042938223744, 0.9991792584587262], Loss = 2.660057884343691\n",
      "Trial 85: Inputs = [0.1440962773806031, 0.07985257804099194, 1.0], Loss = 2.6581704377884448\n",
      "Trial 86: Inputs = [0.9722223874656105, 0.974291678014161, 0.9999470077973109], Loss = 2.658292540593226\n",
      "Trial 87: Inputs = [0.8532738697893245, 0.12953723010261886, 0.9992036782734054], Loss = 2.6600016714110795\n",
      "Trial 88: Inputs = [0.03557893890080609, 0.08679469588672517, 1.0], Loss = 2.658170439716378\n",
      "Trial 89: Inputs = [0.14397888189077437, 0.9580691715313863, 0.9993237181860865], Loss = 2.6597258292657444\n",
      "Trial 90: Inputs = [0.8104228036004907, 0.5591711201334302, 0.9996444130989446], Loss = 2.6589882000831944\n",
      "Trial 91: Inputs = [0.9695108432319689, 0.7376043174635305, 0.9988222743618695], Loss = 2.6608791579021553\n",
      "Trial 92: Inputs = [0.4433911754504567, 0.7608958338071291, 1.0], Loss = 2.6581706351358974\n",
      "Trial 93: Inputs = [0.8252555260727854, 0.15077508068805665, 0.9999395969440378], Loss = 2.6583093371153845\n",
      "Trial 94: Inputs = [0.6265163622319051, 0.028745758856291048, 1.0], Loss = 2.6581704236483503\n",
      "Trial 95: Inputs = [0.9455717324702435, 0.702992850214189, 0.99790273972417], Loss = 2.6629948966074837\n",
      "Trial 96: Inputs = [0.11756920600263508, 0.9807884932227982, 0.999641079145853], Loss = 2.6589959941381935\n",
      "Trial 97: Inputs = [0.5685362605775952, 0.4225742197499588, 0.9751979722890396], Loss = 2.715515866948512\n",
      "Trial 98: Inputs = [0.7344785520249959, 0.8360891389121915, 0.9990109903670318], Loss = 2.660445081865761\n",
      "Trial 99: Inputs = [0.18694687598347612, 1e-07, 1.0], Loss = 2.658170415736136\n",
      "Trial 100: Inputs = [0.5523055904003539, 0.6028280989817053, 1.0], Loss = 2.658170587853718\n",
      "Debug: Optimized lighter ingredients from Bayesian Optimization:\n",
      "[0.8308854257591127, 1e-07, 1.0]\n",
      "Debug: Minimum error achieved:\n",
      "2.658170415736136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8308854257591127, 1e-07, 1.0]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesiann(trial) #error divided by nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8129684c-ab8f-442f-9d04-f13c42875735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized heavy ingredients passed to bayesiann:\n",
      "[6.569365978240967, 5.498148441314697, 5.273582935333252, 5.364184379577637, 4.248894691467285, 3.4599080085754395]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanishah/anaconda3/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [1e-07, 1e-07, 1.0] before, using random point [0.542077266451464, 0.6176488728090731, 0.8124382379430596]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial History (Guessed Inputs and Corresponding Losses):\n",
      "Trial 1: Inputs = [0.5574396817667324, 0.5279668591641179, 0.8561068083898229], Loss = 3.0036423428909083\n",
      "Trial 2: Inputs = [0.7539295569749173, 0.03886934215416717, 0.013633090209335936], Loss = 5.434281513603801\n",
      "Trial 3: Inputs = [0.4633875429059946, 0.5998915348310422, 0.08766771214737554], Loss = 5.19396377489779\n",
      "Trial 4: Inputs = [0.5338848704456247, 0.22192046354122805, 0.7596315432253532], Loss = 3.2417800149891707\n",
      "Trial 5: Inputs = [0.6321626748377455, 0.4943105625354395, 0.09026948893971057], Loss = 5.185687963400658\n",
      "Trial 6: Inputs = [0.8445672333479876, 0.23231749941448326, 0.01668420804724873], Loss = 5.426208716817941\n",
      "Trial 7: Inputs = [0.7059847559792597, 0.09417683337930893, 0.47352110779145984], Loss = 4.0140365712256285\n",
      "Trial 8: Inputs = [0.8488952284938576, 0.883370282414654, 0.604652899095959], Loss = 3.66308818358855\n",
      "Trial 9: Inputs = [0.01724983185009452, 0.607989941634221, 0.03580685495567434], Loss = 5.361015726935123\n",
      "Trial 10: Inputs = [0.7292730386998901, 0.03126578242225793, 0.9314106035325191], Loss = 2.818857946652762\n",
      "Trial 11: Inputs = [1e-07, 1e-07, 1.0], Loss = 2.6592902364123563\n",
      "Trial 12: Inputs = [1.0, 1e-07, 1.0], Loss = 2.659743247788082\n",
      "Trial 13: Inputs = [1e-07, 1.0, 1.0], Loss = 2.663066001075603\n",
      "Trial 14: Inputs = [0.8956907068106529, 0.9827928924234455, 1.0], Loss = 2.676041561284268\n",
      "Trial 15: Inputs = [0.542077266451464, 0.6176488728090731, 0.8124382379430596], Loss = 3.112671990520418\n",
      "Trial 16: Inputs = [0.02117987037539205, 0.1294000805746393, 1.0], Loss = 2.658513855006536\n",
      "Trial 17: Inputs = [0.5085591083252043, 0.007249526494580544, 0.999143338338504], Loss = 2.660160432322445\n",
      "Trial 18: Inputs = [0.022358866865202685, 0.008675846496619895, 0.9969496395839855], Loss = 2.666145363048471\n",
      "Trial 19: Inputs = [0.9873718850616343, 0.05456918823942321, 0.9979182393648078], Loss = 2.6649285908673797\n",
      "Trial 20: Inputs = [0.032275270181085426, 0.025624542157705, 0.9974171771174596], Loss = 2.6649218768585667\n",
      "Trial 21: Inputs = [0.8719683838690289, 0.1465746158272144, 0.9997094297243455], Loss = 2.6609049269070306\n",
      "Trial 22: Inputs = [0.13071748542066325, 0.03313673708380064, 0.999752070328846], Loss = 2.659159840608179\n",
      "Trial 23: Inputs = [0.037257954424113324, 0.0995229600373749, 0.999369799723395], Loss = 2.6600376212621066\n",
      "Trial 24: Inputs = [0.02299010786356007, 0.8480469582165944, 0.9993902491225395], Loss = 2.6627010541681\n",
      "Trial 25: Inputs = [0.06485361594223446, 0.9424373227599673, 0.9995014260468438], Loss = 2.664044371337522\n",
      "Trial 26: Inputs = [0.0901085889002894, 0.022325874799481036, 0.9997454788845177], Loss = 2.659359114425049\n",
      "Trial 27: Inputs = [0.8222793597176878, 0.14716401508999932, 0.9999634085612543], Loss = 2.660008917117026\n",
      "Trial 28: Inputs = [0.006579207792880062, 0.8711832982586191, 0.9998412826086669], Loss = 2.6617987449437734\n",
      "Trial 29: Inputs = [0.957690491071937, 0.28222433993535917, 0.9997900791243111], Loss = 2.662976968731861\n",
      "Trial 30: Inputs = [0.9871956628012439, 0.08661086565999071, 0.9991704073523083], Loss = 2.6623516440563373\n",
      "Trial 31: Inputs = [0.050002864397266526, 0.1825610604654387, 0.9996225499536592], Loss = 2.6591577248830274\n",
      "Trial 32: Inputs = [0.8090912717188727, 0.0744569228125288, 0.9998550337284194], Loss = 2.659619328942022\n",
      "Trial 33: Inputs = [0.009480443492005424, 0.634689056730553, 0.9998844025227605], Loss = 2.6595171791099443\n",
      "Trial 34: Inputs = [0.08649095543811436, 0.33945355376076924, 0.9991753522665663], Loss = 2.6601304091314852\n",
      "Trial 35: Inputs = [0.4800117876085618, 0.3991315947540928, 0.9998735519775981], Loss = 2.6603032379288587\n",
      "Trial 36: Inputs = [0.6392779305773818, 0.8986316166149398, 0.9997575795363068], Loss = 2.670012365086893\n",
      "Trial 37: Inputs = [0.03652524578854487, 0.11517412815213825, 1.0], Loss = 2.6585269187843177\n",
      "Trial 38: Inputs = [0.042750521077244155, 0.7215876195109397, 0.9993762996253202], Loss = 2.661566978101422\n",
      "Trial 39: Inputs = [0.005362417473520266, 0.4241973723475275, 0.9978320510217044], Loss = 2.6632742059604233\n",
      "Trial 40: Inputs = [0.18132046532303248, 0.011218207875545809, 1.0], Loss = 2.658533123283776\n",
      "Trial 41: Inputs = [0.03428940107840024, 0.15248647909168314, 1.0], Loss = 2.6584010336093375\n",
      "Trial 42: Inputs = [0.46113187899535485, 1e-07, 1.0], Loss = 2.6581704809999214\n",
      "Trial 43: Inputs = [0.28024361039329393, 0.08115456721959155, 0.9990636101702494], Loss = 2.6603447825060895\n",
      "Trial 44: Inputs = [0.18199498604808642, 0.667507966936946, 0.9997216358724067], Loss = 2.661200365151703\n",
      "Trial 45: Inputs = [0.5496754081783217, 0.5666861264004502, 0.9993911794234989], Loss = 2.663840189330646\n",
      "Trial 46: Inputs = [0.17212592200377363, 0.22306669363399184, 1.0], Loss = 2.6581752932099554\n",
      "Trial 47: Inputs = [0.1088334701232595, 0.6098932435645781, 0.9998041431456769], Loss = 2.660032859428212\n",
      "Trial 48: Inputs = [0.7468277621737485, 0.017110732455916808, 0.9980764037410315], Loss = 2.6631201959114525\n",
      "Trial 49: Inputs = [0.05542070079025399, 0.46480702000938173, 0.998437980563189], Loss = 2.6621115256119956\n",
      "Trial 50: Inputs = [0.48644794170378336, 0.022032631441469323, 0.9970444611904717], Loss = 2.66498953462373\n",
      "Trial 51: Inputs = [0.2289703563877085, 3.039365928630159e-07, 1.0], Loss = 2.658450000316204\n",
      "Trial 52: Inputs = [0.25964379970088736, 0.425220615432695, 0.9988008282403478], Loss = 2.661798811194047\n",
      "Trial 53: Inputs = [1e-07, 0.25555207430424076, 1.0], Loss = 2.6582199355096594\n",
      "Trial 54: Inputs = [0.5667641802810461, 1e-07, 1.0], Loss = 2.658234089501697\n",
      "Trial 55: Inputs = [0.6366244076182133, 0.09112931408127994, 0.9994068244100546], Loss = 2.660041299023384\n",
      "Trial 56: Inputs = [0.6503932962084191, 0.2870706665389594, 0.998355264119028], Loss = 2.6638707133459945\n",
      "Trial 57: Inputs = [0.4877626853334088, 0.08540861955432205, 1.0], Loss = 2.6582922457686022\n",
      "Trial 58: Inputs = [0.08099364093769432, 0.18587800939840476, 1.0], Loss = 2.658239621389289\n",
      "Trial 59: Inputs = [0.8478628414665679, 0.05518970005050352, 0.9999293587057608], Loss = 2.6595054020776883\n",
      "Trial 60: Inputs = [0.4520234873180657, 0.2659458797109457, 0.9989703837633733], Loss = 2.6612725247230733\n",
      "Trial 61: Inputs = [0.46742481594303453, 0.08746308021046027, 1.0], Loss = 2.6582657351600827\n",
      "Trial 62: Inputs = [0.7053123836829066, 0.269186932980044, 1.0], Loss = 2.660282134352599\n",
      "Trial 63: Inputs = [1e-07, 0.2721241412604689, 1.0], Loss = 2.6581987719342854\n",
      "Trial 64: Inputs = [0.09727176316821919, 0.07309211883423815, 1.0], Loss = 2.658523539196154\n",
      "Trial 65: Inputs = [0.1991996325571717, 0.24005051427362, 1.0], Loss = 2.658205656151339\n",
      "Trial 66: Inputs = [1e-07, 0.2663966971635996, 1.0], Loss = 2.6582054217801905\n",
      "Trial 67: Inputs = [0.704281593771951, 0.056463317333032635, 0.39888537873888386], Loss = 4.2293385432164445\n",
      "Trial 68: Inputs = [0.33191578335004857, 0.20050202773688028, 0.9996682160595751], Loss = 2.6590666426223115\n",
      "Trial 69: Inputs = [0.1575578405105348, 0.19920181261575812, 1.0], Loss = 2.6581722646972223\n",
      "Trial 70: Inputs = [0.3939219605606139, 0.20545019871858994, 0.9997417300870953], Loss = 2.659039566152471\n",
      "Trial 71: Inputs = [0.5904737390868952, 0.4059999422571457, 0.99935139470888], Loss = 2.6623355111456277\n",
      "Trial 72: Inputs = [0.8147274298972995, 1e-07, 1.0], Loss = 2.658852216799944\n",
      "Trial 73: Inputs = [0.38080102214101075, 0.4422315337237344, 1.0], Loss = 2.6597802756743376\n",
      "Trial 74: Inputs = [0.4667962660412607, 0.05139620171100258, 0.9982202024533043], Loss = 2.6622999888813714\n",
      "Trial 75: Inputs = [1e-07, 0.27155359457137945, 1.0], Loss = 2.658199402891593\n",
      "Trial 76: Inputs = [0.3003926975982461, 0.34198785891457273, 0.9992603897219117], Loss = 2.660441245710264\n",
      "Trial 77: Inputs = [0.4627986607392239, 0.08518339155878073, 0.9996980192161213], Loss = 2.658949212598897\n",
      "Trial 78: Inputs = [1e-07, 0.27374272510284203, 1.0], Loss = 2.658197019877001\n",
      "Trial 79: Inputs = [0.7082559976535168, 0.22342531991183717, 0.9996430004128987], Loss = 2.660708189135985\n",
      "Trial 80: Inputs = [0.12267177647470719, 0.175135195951618, 1.0], Loss = 2.6582111611444206\n",
      "Trial 81: Inputs = [0.7726663822699166, 1e-07, 1.0], Loss = 2.658701059406772\n",
      "Trial 82: Inputs = [0.25177072578177395, 0.2669043133135628, 0.999905247095622], Loss = 2.658545910716969\n",
      "Trial 83: Inputs = [0.3172015902499243, 0.05114689280443528, 1.0], Loss = 2.658195220097842\n",
      "Trial 84: Inputs = [1e-07, 0.49794331085002463, 1.0], Loss = 2.6584959478686803\n",
      "Trial 85: Inputs = [0.016611017240463155, 0.30350179763796026, 1.0], Loss = 2.658171236717302\n",
      "Trial 86: Inputs = [0.5134914074649368, 0.09569548203406007, 0.99918557385849], Loss = 2.6602387965962926\n",
      "Trial 87: Inputs = [1e-07, 0.26927801553931086, 1.0], Loss = 2.6582019886986834\n",
      "Trial 88: Inputs = [0.08323424487351404, 0.18937987300494208, 1.0], Loss = 2.6582311501609035\n",
      "Trial 89: Inputs = [0.33558254024418166, 0.10346585175371088, 1.0], Loss = 2.6581736000827374\n",
      "Trial 90: Inputs = [0.04431568579770199, 0.48206277084264243, 1.0], Loss = 2.658556146151759\n",
      "Trial 91: Inputs = [0.04418963938191782, 0.4451391469159251, 0.9998837955270814], Loss = 2.658687626628685\n",
      "Trial 92: Inputs = [0.29719415689921713, 0.45459122378029676, 1.0], Loss = 2.659415667895362\n",
      "Trial 93: Inputs = [1e-07, 0.2838023953346885, 1.0], Loss = 2.6581873874265542\n",
      "Trial 94: Inputs = [1e-07, 0.28416401209091124, 1.0], Loss = 2.658187081481945\n",
      "Trial 95: Inputs = [0.28753240039079736, 0.6665059111871366, 0.9996103943498932], Loss = 2.662258503910892\n",
      "Trial 96: Inputs = [0.15291524110316151, 0.391235742440203, 1.0], Loss = 2.658501161426571\n",
      "Trial 97: Inputs = [0.10084863775749237, 0.07502516834037248, 1.0], Loss = 2.658506409090124\n",
      "Trial 98: Inputs = [0.3255492427683479, 0.3198503074602128, 1.0], Loss = 2.6587191630641764\n",
      "Trial 99: Inputs = [1e-07, 0.2879791596238052, 1.0], Loss = 2.6581840241587344\n",
      "Trial 100: Inputs = [0.3933869340633341, 0.11314490885354678, 1.0], Loss = 2.6582195080402675\n",
      "Debug: Optimized lighter ingredients from Bayesian Optimization:\n",
      "[0.46113187899535485, 1e-07, 1.0]\n",
      "Debug: Minimum error achieved:\n",
      "2.6581704809999214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46113187899535485, 1e-07, 1.0]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayesiann(trial) #changed the error function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79c88a42-9c49-4939-80c1-1e2903c88bf2",
   "metadata": {},
   "source": [
    "^^ With adding noise, there are a few issues:\n",
    "- if I add to an amount, then that could fill up a nutrient amount --> leaving no room for stuff like vanilla extract. However, if I change the noise to only remove values, this isn't really adding noise anymore and isn't random? Do I just subtract a certain amount from each value? So leaving room for everything. But then, do I subtract the same amount from each ingredient or subtract based on its position in the list (so lower index --> more subtracted as its assumed to have a larger amount)? Do we subtract a specific ratio of the ingredient? "
   ]
  },
  {
   "cell_type": "raw",
   "id": "edbe40f2-e6f9-4cd1-b4ab-cba14dc05129",
   "metadata": {},
   "source": [
    "Now, combining these methods into one function:\n",
    "- first get the heavy ingredients through gradient descent\n",
    "- then add noise to this optimized heavy list\n",
    "- then use Bayesian optimization to fine-tune the lighter ingredients\n",
    "- what's next? What if we put the final list through gradient descent again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "31103410-6ae3-4efc-be76-382af90b1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reversy(dictionary_list_for_heavy,target_dict,key_list):\n",
    "\n",
    "    loss, optimized_heavy = running_tf(dictionary_list_for_heavy,target_dict,key_list)\n",
    "    noisy_optimized = add_noise(optimized_heavy)\n",
    "    lighter = bayesiann(noisy_optimized)\n",
    "\n",
    "    return optimized_heavy, lighter, loss\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
